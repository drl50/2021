WEBVTT
Kind: captions
Language: pt-BR

00:00:00.333 --> 00:00:04.667
Agora veremos o segundo
e último tipo de camada

00:00:04.701 --> 00:00:07.167
que precisamos apresentar
antes de construirmos

00:00:07.201 --> 00:00:09.800
as redes neurais
convolucionais.

00:00:09.834 --> 00:00:12.233
As camadas pooling

00:00:12.267 --> 00:00:15.667
usam camada convolucionais
como entrada.

00:00:15.701 --> 00:00:17.567
Camadas convolucionais

00:00:17.601 --> 00:00:19.467
são o empilhamento
de mapas de recurso.

00:00:19.501 --> 00:00:22.867
Nós teremos um mapa
de recurso para cada filtro.

00:00:22.901 --> 00:00:26.800
Um conjunto de dados complicados
com diferentes categorias de objeto

00:00:26.834 --> 00:00:29.767
requer muitos filtros,

00:00:29.801 --> 00:00:33.567
cada um responsável por encontrar
um padrão na imagem.

00:00:33.601 --> 00:00:36.067
Mais filtros significam
um empilhamento maior,

00:00:36.101 --> 00:00:39.133
o que significa que a dimensão
das camadas convolucionais

00:00:39.167 --> 00:00:41.000
pode ficar bem grande.

00:00:41.034 --> 00:00:44.433
Maior dimensão demanda
mais parâmetros,

00:00:44.467 --> 00:00:46.667
que pode levar
ao superajuste.

00:00:46.701 --> 00:00:50.833
Nós precisamos de um método
para reduzir a dimensão.

00:00:50.867 --> 00:00:52.667
Este é o papel
das camadas pooling

00:00:52.701 --> 00:00:55.233
na rede neural
convolucional.

00:00:55.267 --> 00:00:59.333
Nós veremos dois tipos
de camadas pooling.

00:00:59.367 --> 00:01:02.367
O primeiro é
a camada max pooling.

00:01:02.401 --> 00:01:06.867
Ela usa o empilhamento
mapas de recurso como entrada.

00:01:06.901 --> 00:01:11.633
Aqui ampliamos e visualizamos
os três mapas de recurso.

00:01:11.667 --> 00:01:13.667
Assim como as camadas
convolucionais,

00:01:13.701 --> 00:01:16.267
nós definimos o tamanho
da janela e a etapa.

00:01:16.301 --> 00:01:19.267
Neste caso, nós utilizamos
tamanho de janela igual a dois

00:01:19.301 --> 00:01:21.033
e etapas de dois.

00:01:21.067 --> 00:01:23.000
Para construir
a camada max pooling,

00:01:23.034 --> 00:01:25.767
nós trabalhamos com cada
mapa de recurso separadamente.

00:01:25.801 --> 00:01:28.733
Vamos começar
com o primeiro.

00:01:28.767 --> 00:01:32.933
Começamos com nossa janela
no canto superior esquerdo.

00:01:32.967 --> 00:01:36.767
O valor do nó correspondente
na camada max pooling

00:01:36.801 --> 00:01:42.000
é calculada a partir
do maior pixel da janela.

00:01:42.034 --> 00:01:44.900
Neste caso, nós temos
os números um, nove,

00:01:44.934 --> 00:01:47.067
cinco e quatro na janela,

00:01:47.101 --> 00:01:49.400
então nove é o maior.

00:01:50.033 --> 00:01:51.900
Se continuarmos
com este processo,

00:01:51.934 --> 00:01:54.400
e fazer o mesmo com todos
os mapas de recurso,

00:01:54.434 --> 00:01:57.167
a saída será um empilhamento
com a mesma quantidade

00:01:57.201 --> 00:01:58.633
de mapas de recurso,

00:01:58.667 --> 00:02:02.800
mas cada mapa foi reduzido
em largura e altura.

00:02:02.834 --> 00:02:05.967
Neste caso, a largura e a altura
têm a metade

00:02:06.001 --> 00:02:08.700
da camada convolucional
anterior.

00:02:08.734 --> 00:02:11.967
A média global de pooling
é um pouco diferente.

00:02:12.001 --> 00:02:13.800
Para uma camada deste tipo,

00:02:13.834 --> 00:02:16.200
nós não especificamos
nem o tamanho da janela

00:02:16.234 --> 00:02:17.600
nem a etapa.

00:02:17.634 --> 00:02:22.200
Este tipo de pooling possui
redução de dimensão extrema.

00:02:22.234 --> 00:02:24.400
Ele pega o empilhamento
de mapas de recurso

00:02:24.434 --> 00:02:27.033
e calcula a média
do valor dos nós

00:02:27.067 --> 00:02:29.533
para cada mapa
do empilhamento.

00:02:29.567 --> 00:02:32.967
Como antes, analisamos cada mapa
de recurso separadamente

00:02:33.600 --> 00:02:36.300
começando com o primeiro
mapa de recurso.

00:02:36.334 --> 00:02:38.533
Para obter a média
de valor dos nós,

00:02:38.567 --> 00:02:42.400
nós somamos os valores,
que dá 80,

00:02:42.434 --> 00:02:46.633
e dividimos pela
quantidade de nós, que é de 16.

00:02:47.433 --> 00:02:51.233
O resultado aqui é cinco,
que é o valor deste nó.

00:02:52.600 --> 00:02:54.100
Repetindo o processo

00:02:54.134 --> 00:02:56.167
para os dois outros
mapas de recurso,

00:02:56.201 --> 00:02:58.233
nós teremos dois valores
iguais a quatro.

00:02:59.100 --> 00:03:02.000
Então teremos um empilhamento
de mapas de recurso

00:03:02.034 --> 00:03:06.100
no qual cada um foi reduzido
em um valor único.

00:03:06.800 --> 00:03:10.500
Desta forma, vemos que
a média global da camada pooling

00:03:10.534 --> 00:03:13.900
pega um arranjo 3D
e o transforma em um vetor.

00:03:14.800 --> 00:03:17.733
Aqui nós temos um vetor
com três entradas.

00:03:18.867 --> 00:03:22.033
Vamos resumir o que aprendemos
com uma analogia de comida.

00:03:22.733 --> 00:03:26.433
Pense na camada convolucional
como o empilhamento de panquecas,

00:03:26.467 --> 00:03:29.833
sendo que cada uma
é um mapa de recurso.

00:03:29.867 --> 00:03:31.933
As camadas pooling pegam
o empilhamento

00:03:31.967 --> 00:03:35.367
e nos devolve a mesma
quantidade de panquecas,

00:03:35.401 --> 00:03:40.033
mas elas serão menores
em largura e altura.

00:03:40.067 --> 00:03:45.500
Camadas globais não pooling
fazem uma redução moderada,

00:03:45.534 --> 00:03:49.067
na qual cada panqueca
fica com a metade da altura

00:03:49.101 --> 00:03:52.600
e da largura da entrada.

00:03:53.400 --> 00:03:56.767
As camadas globais pooling
reduzem cada panqueca

00:03:56.801 --> 00:03:59.767
a uma migalha,

00:03:59.801 --> 00:04:04.233
mas nós ainda temos uma migalha
para cada panqueca de entrada.

00:04:04.267 --> 00:04:08.133
Neste vídeo nós vimos
dois tipos de camadas pooling,

00:04:08.167 --> 00:04:10.367
mas você pode ler
sobre as outras

00:04:10.401 --> 00:04:13.167
na documentação do Keras
do link abaixo.

