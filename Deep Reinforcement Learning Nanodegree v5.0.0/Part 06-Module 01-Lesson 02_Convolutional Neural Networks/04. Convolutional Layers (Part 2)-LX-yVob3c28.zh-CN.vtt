WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:02.399
看看这张小狗图像

00:00:02.399 --> 00:00:08.400
图像中的单个区域可能有很多需要我们检测的规律

00:00:08.400 --> 00:00:11.115
例如这个区域

00:00:11.115 --> 00:00:13.150
这个区域有牙齿

00:00:13.150 --> 00:00:15.484
几根胡须和舌头

00:00:15.484 --> 00:00:18.710
这样的话 要理解这幅图像

00:00:18.710 --> 00:00:22.875
我们就需要用于检测所有这三种特性的过滤器

00:00:22.875 --> 00:00:26.714
牙齿 胡须和舌头分别对应一个过滤器

00:00:26.714 --> 00:00:30.620
还记得之前的单个卷积过滤器吗？

00:00:30.620 --> 00:00:34.954
添加另一个过滤器几乎完全一样

00:00:34.954 --> 00:00:40.259
我们只需在卷积层中填充另一组节点

00:00:40.259 --> 00:00:43.019
这个集合具有自己的共享权重集

00:00:43.020 --> 00:00:46.755
与上方蓝色节点的权重不同

00:00:46.755 --> 00:00:48.855
实际上 在一个卷积层中拥有数十个或数百个

00:00:48.854 --> 00:00:52.890
这种节点集合是很常见的

00:00:52.890 --> 00:00:55.710
每个都对应自己的过滤器

00:00:55.710 --> 00:01:00.060
我们现在运行一些代码 看看这些集合的代码如何

00:01:00.060 --> 00:01:04.094
毕竟 每个的形成方式都和图像的一样

00:01:04.094 --> 00:01:06.704
即值矩阵

00:01:06.704 --> 00:01:10.429
我们将可视化 Jupyter Notebook 的输出

00:01:10.430 --> 00:01:14.340
如果你愿意的话 可以点击下面的链接跟着操作

00:01:14.340 --> 00:01:20.430
假设我们要处理的输入图像是优达学城的无人驾驶汽车

00:01:20.430 --> 00:01:22.485
我们使用四个过滤器

00:01:22.484 --> 00:01:26.515
每个都高 4 个像素 宽 4 个像素

00:01:26.515 --> 00:01:31.290
每个过滤器将在图像的宽和高上卷积

00:01:31.290 --> 00:01:36.165
以在卷积层中形成整个节点集合

00:01:36.165 --> 00:01:39.290
这里 因为我们有四个过滤器

00:01:39.290 --> 00:01:41.745
因此将有四组节点

00:01:41.745 --> 00:01:44.040
在实际操作中

00:01:44.040 --> 00:01:48.330
我们将这四个集合称为特征图或激活图

00:01:48.329 --> 00:01:50.879
当我们可视化这些特征图时

00:01:50.879 --> 00:01:54.214
我们看到它们看起来像过滤后的图像

00:01:54.215 --> 00:01:57.075
即我们从原始图像中拿走

00:01:57.075 --> 00:02:00.045
所有复杂的密集信息

00:02:00.045 --> 00:02:02.144
并在每个集合中

00:02:02.144 --> 00:02:06.189
输出信息更少的更简单图像

00:02:06.189 --> 00:02:08.789
通过观察这些过滤器的结构

00:02:08.789 --> 00:02:12.534
可以发现前两个过滤器发现了垂直边缘

00:02:12.534 --> 00:02:16.439
后两个过滤器检测到图像中的水平边缘

00:02:16.439 --> 00:02:19.439
特征图中浅色的值

00:02:19.439 --> 00:02:23.094
表示在图像中发现了过滤器中的规律

00:02:23.094 --> 00:02:26.039
你能将每个特征图中的浅色区域

00:02:26.039 --> 00:02:30.564
与原始图像的相应区域进行匹配吗？

00:02:30.564 --> 00:02:33.500
例如在这个激活图中

00:02:33.500 --> 00:02:38.759
我们可以看到一条清晰的白色线条 表示汽车的右侧边缘

00:02:38.759 --> 00:02:43.620
这是因为汽车图像中的所有对应区域与过滤器很相似

00:02:43.620 --> 00:02:47.129
垂直浅色像素的左侧是

00:02:47.129 --> 00:02:51.359
垂直深色像素线条

00:02:51.360 --> 00:02:55.500
如果思考下 会发现图像中的边缘

00:02:55.500 --> 00:03:00.090
显示为在深色像素旁边的浅色像素线条

00:03:00.090 --> 00:03:03.900
例如这个图像包含很多可以被之前定义的

00:03:03.900 --> 00:03:08.534
四个过滤器之一发现或检测到的区域

00:03:08.534 --> 00:03:13.754
在 CNN 中充当边缘检测器的函数非常重要

00:03:13.754 --> 00:03:15.870
稍后我们会继续讲解

00:03:15.870 --> 00:03:19.444
现在我们知道什么是

00:03:19.444 --> 00:03:23.215
将灰度图像作为输入的卷积层了

00:03:23.215 --> 00:03:25.670
那么彩色图像呢？

00:03:25.669 --> 00:03:31.859
我们知道灰度图像被计算机解读为

00:03:31.860 --> 00:03:34.535
具有宽和高的二维数组

00:03:34.534 --> 00:03:39.254
彩色图像则被计算机解读为

00:03:39.254 --> 00:03:42.509
具有宽度 高度和深度的三维数组

00:03:42.509 --> 00:03:47.189
对于 RGB 图像 深度是 3

00:03:47.189 --> 00:03:55.365
这些三维矩阵可以理解为三个二维矩阵堆叠到了一起

00:03:55.365 --> 00:03:58.465
这些矩阵对应的是图像的红色

00:03:58.465 --> 00:04:01.450
绿色和蓝色通道

00:04:01.449 --> 00:04:05.489
那么如何对彩色图像进行卷积处理呢？

00:04:05.490 --> 00:04:08.534
和灰度图像一样

00:04:08.534 --> 00:04:13.454
依然在图像上水平及垂直地移动过滤器

00:04:13.455 --> 00:04:18.495
但是现在过滤器本身是三维的

00:04:18.495 --> 00:04:24.240
对于图像数组中每个水平和垂直位置的颜色通道都有一个值

00:04:24.240 --> 00:04:30.088
就像我们将彩色图像看做三个二维矩阵的堆叠一样

00:04:30.088 --> 00:04:34.800
也可以将过滤器看做三个二维矩阵的堆叠

00:04:34.800 --> 00:04:38.605
彩色图像和过滤器都拥有红色

00:04:38.605 --> 00:04:40.670
绿色和蓝色通道

00:04:40.670 --> 00:04:46.680
要从特征图中获取对应于该过滤器的节点值

00:04:46.680 --> 00:04:49.905
流程和之前的差不多

00:04:49.904 --> 00:04:53.959
只是现在求和的项是之前的三倍

00:04:53.959 --> 00:04:58.049
这里计算的是彩色图像上

00:04:58.050 --> 00:05:01.800
一个过滤器的

00:05:01.800 --> 00:05:05.204
卷积层中一个节点的值

00:05:05.204 --> 00:05:08.250
如果要表示具有多个过滤器的彩色图像

00:05:08.250 --> 00:05:15.149
而不是对应一个过滤器的一个三维数组

00:05:15.149 --> 00:05:20.054
我们需要定义多个三维数组 每个定义一个过滤器

00:05:20.055 --> 00:05:23.040
这里我们描绘了三个过滤器

00:05:23.040 --> 00:05:29.025
每个都是一个三维数组 可以看做三个二维数组的堆叠

00:05:29.024 --> 00:05:32.024
现在到了精彩的部分了

00:05:32.024 --> 00:05:36.599
你可以将沿着相同线条的卷积层中的每个特征图

00:05:36.600 --> 00:05:41.805
看做一个图像通道 将它们堆叠就能获得三维数组

00:05:41.805 --> 00:05:45.720
然后可以将此三维数组

00:05:45.720 --> 00:05:49.560
当做依然是另一个卷积层的输入

00:05:49.560 --> 00:05:54.920
以便从我们在第一个卷积层中发现的规律中发现规律

00:05:54.920 --> 00:06:01.439
然后可以继续这么做 从规律中发现规律 然后继续从规律中发现规律

00:06:01.439 --> 00:06:05.040
注意 从某种程度上来说

00:06:05.040 --> 00:06:09.450
卷积层和你在上一部分见到的密集层区别不大

00:06:09.449 --> 00:06:12.584
密集层是完全连接的

00:06:12.584 --> 00:06:17.099
意味着节点与前一层级中的每个节点相连

00:06:17.100 --> 00:06:20.090
卷积层是局部相连的

00:06:20.089 --> 00:06:25.824
节点仅与上一层级中的一小部分节点相连

00:06:25.824 --> 00:06:30.115
卷积层还具有参数共享特性

00:06:30.115 --> 00:06:34.410
但是对于卷积层和密集层来说

00:06:34.410 --> 00:06:36.780
推理的工作原理是一样的

00:06:36.779 --> 00:06:41.884
二者的权重和偏差一开始都是随机生成的

00:06:41.884 --> 00:06:46.889
对于 CNN 来说 权重是卷积过滤器形式

00:06:46.889 --> 00:06:49.108
这些过滤器是随机生成的

00:06:49.108 --> 00:06:53.199
一开始检测的规律也是随机的

00:06:53.199 --> 00:06:59.349
和 NLP 一样 当我们构建 CNN 时 始终会指定损失函数

00:06:59.350 --> 00:07:05.545
对于多类别分类 将是分类交叉熵损失

00:07:05.545 --> 00:07:09.324
然后通过反向传播训练模型

00:07:09.324 --> 00:07:15.375
在每个周期都会更新过滤器 以便设定可以最小化损失函数的值

00:07:15.375 --> 00:07:19.110
换句话说 CNN 根据损失函数

00:07:19.110 --> 00:07:22.935
确定它需要检测什么样的规律

00:07:22.935 --> 00:07:27.240
稍后我们将可视化这些规律

00:07:27.240 --> 00:07:29.235
例如查看我们的数据集是否包含狗狗

00:07:29.235 --> 00:07:34.495
CNN 能够自己学习看起来像狗狗的过滤器

00:07:34.495 --> 00:07:39.209
强调下 对于 CNN 我们不会指定过滤器值

00:07:39.209 --> 00:07:44.564
或者告诉 CNN 它需要检测什么样的规律

00:07:44.564 --> 00:07:47.589
而是从数据中学习

