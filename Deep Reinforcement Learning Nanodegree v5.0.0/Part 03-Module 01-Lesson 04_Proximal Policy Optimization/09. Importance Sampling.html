<!-- udacimak v1.4.4 -->
<!DOCTYPE html>
<html lang="en">
 <head>
  <meta charset="utf-8"/>
  <meta content="width=device-width, initial-scale=1.0" name="viewport"/>
  <meta content="ie=edge" http-equiv="X-UA-Compatible"/>
  <title>
   Importance Sampling
  </title>
  <link href="../assets/css/bootstrap.min.css" rel="stylesheet"/>
  <link href="../assets/css/plyr.css" rel="stylesheet"/>
  <link href="../assets/css/katex.min.css" rel="stylesheet"/>
  <link href="../assets/css/jquery.mCustomScrollbar.min.css" rel="stylesheet"/>
  <link href="../assets/css/styles.css" rel="stylesheet"/>
  <link href="../assets/img/udacimak.png" rel="shortcut icon" type="image/png">
  </link>
 </head>
 <body>
  <div class="wrapper">
   <nav id="sidebar">
    <div class="sidebar-header">
     <h3>
      Proximal Policy Optimization
     </h3>
    </div>
    <ul class="sidebar-list list-unstyled CTAs">
     <li>
      <a class="article" href="../index.html">
       Back to Home
      </a>
     </li>
    </ul>
    <ul class="sidebar-list list-unstyled components">
     <li class="">
      <a href="01. Instructor Introduction.html">
       01. Instructor Introduction
      </a>
     </li>
     <li class="">
      <a href="02. Lesson Preview.html">
       02. Lesson Preview
      </a>
     </li>
     <li class="">
      <a href="03. Beyond REINFORCE.html">
       03. Beyond REINFORCE
      </a>
     </li>
     <li class="">
      <a href="04. Noise Reduction.html">
       04. Noise Reduction
      </a>
     </li>
     <li class="">
      <a href="05. Credit Assignment.html">
       05. Credit Assignment
      </a>
     </li>
     <li class="">
      <a href="06. Policy Gradient Quiz.html">
       06. Policy Gradient Quiz
      </a>
     </li>
     <li class="">
      <a href="07. pong with REINFORCE (code walkthrough).html">
       07. pong with REINFORCE (code walkthrough)
      </a>
     </li>
     <li class="">
      <a href="08. pong with REINFORCE (workspace).html">
       08. pong with REINFORCE (workspace)
      </a>
     </li>
     <li class="">
      <a href="09. Importance Sampling.html">
       09. Importance Sampling
      </a>
     </li>
     <li class="">
      <a href="10. PPO part 1- The Surrogate Function.html">
       10. PPO part 1- The Surrogate Function
      </a>
     </li>
     <li class="">
      <a href="11. PPO part 2- Clipping Policy Updates.html">
       11. PPO part 2- Clipping Policy Updates
      </a>
     </li>
     <li class="">
      <a href="12. PPO summary.html">
       12. PPO summary
      </a>
     </li>
     <li class="">
      <a href="13. pong with PPO (code walkthrough).html">
       13. pong with PPO (code walkthrough)
      </a>
     </li>
     <li class="">
      <a href="14. pong with PPO (workspace).html">
       14. pong with PPO (workspace)
      </a>
     </li>
    </ul>
    <ul class="sidebar-list list-unstyled CTAs">
     <li>
      <a class="article" href="../index.html">
       Back to Home
      </a>
     </li>
    </ul>
   </nav>
   <div id="content">
    <header class="container-fluild header">
     <div class="container">
      <div class="row">
       <div class="col-12">
        <div class="align-items-middle">
         <button class="btn btn-toggle-sidebar" id="sidebarCollapse" type="button">
          <div>
          </div>
          <div>
          </div>
          <div>
          </div>
         </button>
         <h1 style="display: inline-block">
          09. Importance Sampling
         </h1>
        </div>
       </div>
      </div>
     </div>
    </header>
    <main class="container">
     <div class="row">
      <div class="col-12">
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <h1 id="importance-sampling">
          Importance Sampling
         </h1>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
         <p>
          Importance Sampling
         </p>
        </h3>
        <video controls="">
         <source src="09. Importance Sampling-cYPvWriOPIk.mp4" type="video/mp4"/>
         <track default="true" kind="subtitles" label="en" src="09. Importance Sampling-cYPvWriOPIk.en.vtt" srclang="en"/>
        </video>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <h2 id="1-policy-update-in-reinforce">
          1. Policy Update in REINFORCE
         </h2>
         <p>
          Let’s go back to the REINFORCE algorithm. We start with a policy,
          <span class="mathquill ud-math">
           \pi_\theta
          </span>
          , then using that policy, we generate a trajectory (or multiple ones to reduce noise)
          <span class="mathquill ud-math">
           (s_t, a_t, r_t)
          </span>
          . Afterward, we compute a policy gradient,
          <span class="mathquill ud-math">
           g
          </span>
          , and update
          <span class="mathquill ud-math">
           \theta' \leftarrow \theta + \alpha g
          </span>
          .
         </p>
         <p>
          At this point, the trajectories we’ve just generated are simply thrown away. If we want to update our policy again, we would need to generate new trajectories once more, using the updated policy.
         </p>
         <p>
          You might ask, why is all this necessary? It’s because we need to compute the gradient for the current policy, and to do that the trajectories need to be representative of the current policy.
         </p>
         <p>
          But this sounds a little wasteful. What if we could somehow recycle the old trajectories, by modifying them so that they are representative of the new policy? So that instead of just throwing them away, we recycle them!
         </p>
         <p>
          Then we could just reuse the recycled trajectories to compute gradients, and to update our policy, again, and again. This would make updating the policy a lot more efficient.
          <br/>
          So, how exactly would that work?
         </p>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <h2 id="2-importance-sampling">
          2. Importance Sampling
         </h2>
         <p>
          This is where importance sampling comes in. Let’s look at the trajectories we generated using the policy
          <span class="mathquill ud-math">
           \pi_\theta
          </span>
          . It had a probability
          <span class="mathquill ud-math">
           P(\tau;\theta)
          </span>
          , to be sampled.
         </p>
         <p>
          Now Just by chance, the same trajectory can be sampled under the new policy, with a different probability
          <span class="mathquill ud-math">
           P(\tau;\theta')
          </span>
         </p>
         <p>
          Imagine we want to compute the average of some quantity, say
          <span class="mathquill ud-math">
           f(\tau)
          </span>
          . We could simply generate trajectories from the new policy, compute
          <span class="mathquill ud-math">
           f(\tau)
          </span>
          and average them.
         </p>
         <p>
          Mathematically, this is equivalent to adding up all the
          <span class="mathquill ud-math">
           f(\tau)
          </span>
          , weighted by a probability of sampling each trajectory under the new policy.
         </p>
         <div class="mathquill">
          \sum_\tau P(\tau;\theta') f(\tau)
         </div>
         <p>
          Now we could modify this equation, by multiplying and dividing by the same number,
          <span class="mathquill ud-math">
           P(\tau;\theta)
          </span>
          and rearrange the terms.
         </p>
         <div class="mathquill">
          \sum_\tau \overbrace{P(\tau;\theta)}^{
\begin{matrix}
\scriptsize
\textrm{sampling under}\\
\scriptsize
\textrm{old policy }
\pi_\theta
\end{matrix}
} 
\overbrace{\frac{P(\tau;\theta')}{P(\tau;\theta)}}^{
\begin{matrix}
\scriptsize 
\textrm{re-weighting}\\
\scriptsize
\textrm{factor}
\end{matrix}
}
 f(\tau)
         </div>
         <p>
          It doesn’t look we’ve done much. But written in this way, we can reinterpret the first part as the coefficient for sampling under the old policy, with an extra re-weighting factor, in addition to just averaging.
         </p>
         <p>
          Intuitively, this tells us we can use old trajectories for computing averages for new policy, as long as we add this extra re-weighting factor, that takes into account how under or over–represented each trajectory is under the new policy compared to the old one.
         </p>
         <p>
          The same tricks are used frequently across statistics, where the re-weighting factor is included to un-bias surveys and voting predictions.
         </p>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <h2 id="3-the-re-weighting-factor">
          3. The re-weighting factor
         </h2>
         <p>
          Now Let’s a closer look at the re-weighting factor.
         </p>
         <div class="mathquill">
          \frac{P(\tau;\theta')}{P(\tau;\theta)}
=\frac
{\pi_{\theta'}(a_1|s_1)\, \pi_{\theta'}(a_2|s_2)\, \pi_{\theta'}(a_3|s_3)\,...}
{\pi_\theta(a_1|s_1) \, \pi_\theta(a_2|s_2)\, \pi_\theta(a_2|s_2)\, ...}
         </div>
         <p>
          Because each trajectory contains many steps, the probability contains a chain of products of each policy at different time-step.
         </p>
         <p>
          This formula is a bit complicated. But there is a bigger problem. When some of policy gets close to zero, the re-weighting factor can become close to zero, or worse, close to 1 over 0 which diverges to infinity.
         </p>
         <p>
          When this happens, the re-weighting trick becomes unreliable. So, In practice, we want to make sure the re-weighting factor is not too far from 1 when we utilize importance sampling
         </p>
        </div>
       </div>
       <div class="divider">
       </div>
      </div>
      <div class="col-12">
       <p class="text-right">
        <a class="btn btn-outline-primary mt-4" href="10. PPO part 1- The Surrogate Function.html" role="button">
         Next Concept
        </a>
       </p>
      </div>
     </div>
    </main>
    <footer class="footer">
     <div class="container">
      <div class="row">
       <div class="col-12">
        <p class="text-center">
         udacity2.0 If you need the newest courses Plase add me wechat: udacity6
        </p>
       </div>
      </div>
     </div>
    </footer>
   </div>
  </div>
  <script src="../assets/js/jquery-3.3.1.min.js">
  </script>
  <script src="../assets/js/plyr.polyfilled.min.js">
  </script>
  <script src="../assets/js/bootstrap.min.js">
  </script>
  <script src="../assets/js/jquery.mCustomScrollbar.concat.min.js">
  </script>
  <script src="../assets/js/katex.min.js">
  </script>
  <script>
   // Initialize Plyr video players
    const players = Array.from(document.querySelectorAll('video')).map(p => new Plyr(p));

    // render math equations
    let elMath = document.getElementsByClassName('mathquill');
    for (let i = 0, len = elMath.length; i < len; i += 1) {
      const el = elMath[i];

      katex.render(el.textContent, el, {
        throwOnError: false
      });
    }

    // this hack will make sure Bootstrap tabs work when using Handlebars
    if ($('#question-tabs').length && $('#user-answer-tabs').length) {
      $("#question-tabs a.nav-link").on('click', function () {
        $("#question-tab-contents .tab-pane").hide();
        $($(this).attr("href")).show();
      });
      $("#user-answer-tabs a.nav-link").on('click', function () {
        $("#user-answer-tab-contents .tab-pane").hide();
        $($(this).attr("href")).show();
      });
    } else {
      $("a.nav-link").on('click', function () {
        $(".tab-pane").hide();
        $($(this).attr("href")).show();
      });
    }

    // side bar events
    $(document).ready(function () {
      $("#sidebar").mCustomScrollbar({
        theme: "minimal"
      });

      $('#sidebarCollapse').on('click', function () {
        $('#sidebar, #content').toggleClass('active');
        $('.collapse.in').toggleClass('in');
        $('a[aria-expanded=true]').attr('aria-expanded', 'false');
      });

      // scroll to first video on page loading
      if ($('video').length) {
        $('html,body').animate({ scrollTop: $('div.plyr').prev().offset().top});
      }

      // auto play first video: this may not work with chrome/safari due to autoplay policy
      if (players && players.length > 0) {
        players[0].play();
      }

      // scroll sidebar to current concept
      const currentInSideBar = $( "ul.sidebar-list.components li a:contains('09. Importance Sampling')" )
      currentInSideBar.css( "text-decoration", "underline" );
      $("#sidebar").mCustomScrollbar('scrollTo', currentInSideBar);
    });
  </script>
 </body>
</html>
