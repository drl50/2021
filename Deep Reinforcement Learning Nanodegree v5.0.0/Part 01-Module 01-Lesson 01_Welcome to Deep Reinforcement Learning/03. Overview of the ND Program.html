<!-- udacimak v1.4.4 -->
<!DOCTYPE html>
<html lang="en">
 <head>
  <meta charset="utf-8"/>
  <meta content="width=device-width, initial-scale=1.0" name="viewport"/>
  <meta content="ie=edge" http-equiv="X-UA-Compatible"/>
  <title>
   Overview of the ND Program
  </title>
  <link href="../assets/css/bootstrap.min.css" rel="stylesheet"/>
  <link href="../assets/css/plyr.css" rel="stylesheet"/>
  <link href="../assets/css/katex.min.css" rel="stylesheet"/>
  <link href="../assets/css/jquery.mCustomScrollbar.min.css" rel="stylesheet"/>
  <link href="../assets/css/styles.css" rel="stylesheet"/>
  <link href="../assets/img/udacimak.png" rel="shortcut icon" type="image/png">
  </link>
 </head>
 <body>
  <div class="wrapper">
   <nav id="sidebar">
    <div class="sidebar-header">
     <h3>
      Welcome to Deep Reinforcement Learning
     </h3>
    </div>
    <ul class="sidebar-list list-unstyled CTAs">
     <li>
      <a class="article" href="../index.html">
       Back to Home
      </a>
     </li>
    </ul>
    <ul class="sidebar-list list-unstyled components">
     <li class="">
      <a href="01. Welcome to the Deep Reinforcement Learning Nanodegree.html">
       01. Welcome to the Deep Reinforcement Learning Nanodegree
      </a>
     </li>
     <li class="">
      <a href="02. RL in the Real World.html">
       02. RL in the Real World
      </a>
     </li>
     <li class="">
      <a href="03. Overview of the ND Program.html">
       03. Overview of the ND Program
      </a>
     </li>
     <li class="">
      <a href="04. Projects You Will Build.html">
       04. Projects You Will Build
      </a>
     </li>
     <li class="">
      <a href="05. Play Tennis!.html">
       05. Play Tennis!
      </a>
     </li>
     <li class="">
      <a href="06. Udacity Support.html">
       06. Udacity Support
      </a>
     </li>
     <li class="">
      <a href="07. Community Guidelines.html">
       07. Community Guidelines
      </a>
     </li>
    </ul>
    <ul class="sidebar-list list-unstyled CTAs">
     <li>
      <a class="article" href="../index.html">
       Back to Home
      </a>
     </li>
    </ul>
   </nav>
   <div id="content">
    <header class="container-fluild header">
     <div class="container">
      <div class="row">
       <div class="col-12">
        <div class="align-items-middle">
         <button class="btn btn-toggle-sidebar" id="sidebarCollapse" type="button">
          <div>
          </div>
          <div>
          </div>
          <div>
          </div>
         </button>
         <h1 style="display: inline-block">
          03. Overview of the ND Program
         </h1>
        </div>
       </div>
      </div>
     </div>
    </header>
    <main class="container">
     <div class="row">
      <div class="col-12">
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <h1 id="overview-of-the-nd-program">
          Overview of the ND Program
         </h1>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <p>
          The Deep Reinforcement Learning Nanodegree program is divided into four parts, giving you a thorough understanding of deep reinforcement learning, and covering some of the major topics.
         </p>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <h2 id="-part-1-foundations-of-reinforcement-learning">
          ## Part 1: Foundations of Reinforcement Learning
         </h2>
         <p>
          The first part begins with a simple introduction to reinforcement learning.  You'll learn how to define real-world problems as
          <strong>
           Markov Decision Processes (MDPs)
          </strong>
          , so that they can be solved with reinforcement learning.
         </p>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <figure class="figure">
          <img alt="How might we use [reinforcement learning](https://arxiv.org/pdf/1803.05580.pdf) to teach a robot to walk? ([Source](https://spectrum.ieee.org/automaton/robotics/industrial-robots/agility-robotics-introduces-cassie-a-dynamic-and-talented-robot-delivery-ostrich))" class="img img-fluid" src="img/mjg2mzcyma.gif"/>
          <figcaption class="figure-caption">
           <p>
            How might we use
            <a href="https://arxiv.org/pdf/1803.05580.pdf" rel="noopener noreferrer" target="_blank">
             reinforcement learning
            </a>
            to teach a robot to walk? (
            <a href="https://spectrum.ieee.org/automaton/robotics/industrial-robots/agility-robotics-introduces-cassie-a-dynamic-and-talented-robot-delivery-ostrich" rel="noopener noreferrer" target="_blank">
             Source
            </a>
            )
           </p>
          </figcaption>
         </figure>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <p>
          Then, you'll implement classical methods such as
          <strong>
           SARSA
          </strong>
          and
          <strong>
           Q-learning
          </strong>
          to solve several environments in OpenAI Gym.  You'll then explore how to use techniques such as
          <strong>
           tile coding
          </strong>
          and
          <strong>
           coarse coding
          </strong>
          to expand the size of the problems that can be solved with traditional reinforcement learning algorithms.
         </p>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <figure class="figure">
          <img alt="Train a car to navigate a steep hill using Q-learning." class="img img-fluid" src="img/mountain-car-cts.gif"/>
          <figcaption class="figure-caption">
           <p>
            Train a car to navigate a steep hill using Q-learning.
           </p>
          </figcaption>
         </figure>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <h2 id="-part-2-value-based-methods">
          ## Part 2: Value-Based Methods
         </h2>
         <p>
          In the second part, you'll learn how to leverage neural networks when solving complex problems using the
          <strong>
           Deep Q-Networks (DQN)
          </strong>
          algorithm.  You will also learn about modifications such as
          <strong>
           double Q-learning
          </strong>
          ,
          <strong>
           prioritized experience replay
          </strong>
          , and
          <strong>
           dueling networks
          </strong>
          . Then, you'll use what you’ve learned to create an artificially intelligent game-playing agent that can navigate a spaceship!
         </p>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <figure class="figure">
          <img alt="Use the DQN algorithm to train a spaceship to land safely on a planet." class="img img-fluid" src="img/lunar-lander.gif"/>
          <figcaption class="figure-caption">
           <p>
            Use the DQN algorithm to train a spaceship to land safely on a planet.
           </p>
          </figcaption>
         </figure>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <p>
          You'll learn from experts at NVIDIA's Deep Learning Institute how to apply your new skills to robotics applications.  Using a
          <a href="http://gazebosim.org" rel="noopener noreferrer" target="_blank">
           Gazebo
          </a>
          simulation, you will train a rover to navigate an environment without running into walls.
         </p>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <figure class="figure">
          <img alt="Learn from experts at NVIDIA how to navigate a rover!" class="img img-fluid" src="img/output.gif"/>
          <figcaption class="figure-caption">
           <p>
            Learn from experts at NVIDIA how to navigate a rover!
           </p>
          </figcaption>
         </figure>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <p>
          You'll also get the
          <strong>
           first project
          </strong>
          , where you'll write an algorithm that teaches an agent to navigate a large world.
         </p>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <figure class="figure">
          <img alt="In Project 1, you will train an agent to collect yellow bananas while avoiding blue bananas." class="img img-fluid" src="img/banana.gif"/>
          <figcaption class="figure-caption">
           <p>
            In Project 1, you will train an agent to collect yellow bananas while avoiding blue bananas.
           </p>
          </figcaption>
         </figure>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <p>
          All of the projects in this Nanodegree program use the rich simulation environments from the
          <a href="https://blogs.unity3d.com/2017/09/19/introducing-unity-machine-learning-agents/" rel="noopener noreferrer" target="_blank">
           Unity Machine Learning Agents (ML-Agents)
          </a>
          software development kit (SDK).  You will learn more about ML-Agents in the next concept.
         </p>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <h2 id="-part-3-policy-based-methods">
          ## Part 3: Policy-Based Methods
         </h2>
         <p>
          In the third part, you'll learn about policy-based and actor-critic methods such as
          <strong>
           Proximal Policy Optimization (PPO)
          </strong>
          ,
          <strong>
           Advantage Actor-Critic (A2C)
          </strong>
          , and
          <strong>
           Deep Deterministic Policy Gradients (DDPG)
          </strong>
          .  You’ll also learn about optimization techniques such as
          <strong>
           evolution strategies
          </strong>
          and
          <strong>
           hill climbing
          </strong>
          .
         </p>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <figure class="figure">
          <img alt="Use Deep Deterministic Policy Gradients (DDPG) to train a robot to walk." class="img img-fluid" src="img/bipedal-walker.gif"/>
          <figcaption class="figure-caption">
           <p>
            Use Deep Deterministic Policy Gradients (DDPG) to train a robot to walk.
           </p>
          </figcaption>
         </figure>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <p>
          You'll learn from experts at NVIDIA about the active research that they are doing, to determine how to apply deep reinforcement learning techniques to finance.  In particular, you'll explore an algorithm for optimal execution of portfolio transactions.
         </p>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <p>
          You'll also get the
          <strong>
           second project
          </strong>
          , where you'll write an algorithm to train a robotic arm to reach moving target positions.
         </p>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <figure class="figure">
          <img alt="In Project 2, you will train a robotic arm to reach target locations." class="img img-fluid" src="img/reacher.gif"/>
          <figcaption class="figure-caption">
           <p>
            In Project 2, you will train a robotic arm to reach target locations.
           </p>
          </figcaption>
         </figure>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <h2 id="-part-4-multi-agent-reinforcement-learning">
          ## Part 4: Multi-Agent Reinforcement Learning
         </h2>
         <p>
          Most of reinforcement learning is concerned with a single agent that seeks to demonstrate proficiency at a single task.  In this agent's environment, there are no other agents.  However, if we'd like our agents to become truly intelligent, they must be able to communicate with and learn from other agents.  In the final part of this nanodegree, we will extend the traditional framework to include multiple agents.
         </p>
         <p>
          You'll also learn all about
          <strong>
           Monte Carlo Tree Search (MCTS)
          </strong>
          and master the skills behind DeepMind's AlphaZero.
         </p>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <figure class="figure">
          <img alt="Use Monte Carlo Tree Search to play Connect 4. ([Source](https://github.com/Alfo5123/Connect4))" class="img img-fluid" src="img/game-example.gif"/>
          <figcaption class="figure-caption">
           <p>
            Use Monte Carlo Tree Search to play Connect 4. (
            <a href="https://github.com/Alfo5123/Connect4" rel="noopener noreferrer" target="_blank">
             Source
            </a>
            )
           </p>
          </figcaption>
         </figure>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <p>
          You'll also get the
          <strong>
           third project
          </strong>
          , where you'll write an algorithm to train a pair of agents to play tennis.
         </p>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <figure class="figure">
          <img alt="In Project 3, you will train a pair of agents to play tennis. ([Source](https://blogs.unity3d.com/2017/09/19/introducing-unity-machine-learning-agents/))" class="img img-fluid" src="img/68747470733a2f2f626c6f67732e756e69747933642e636f6d2f77702d636f6e74656e742f75706c6f6164732f323031372f"/>
          <figcaption class="figure-caption">
           <p>
            In Project 3, you will train a pair of agents to play tennis. (
            <a href="https://blogs.unity3d.com/2017/09/19/introducing-unity-machine-learning-agents/" rel="noopener noreferrer" target="_blank">
             Source
            </a>
            )
           </p>
          </figcaption>
         </figure>
        </div>
       </div>
       <div class="divider">
       </div>
      </div>
      <div class="col-12">
       <p class="text-right">
        <a class="btn btn-outline-primary mt-4" href="04. Projects You Will Build.html" role="button">
         Next Concept
        </a>
       </p>
      </div>
     </div>
    </main>
    <footer class="footer">
     <div class="container">
      <div class="row">
       <div class="col-12">
        <p class="text-center">
         udacity2.0 If you need the newest courses Plase add me wechat: udacity6
        </p>
       </div>
      </div>
     </div>
    </footer>
   </div>
  </div>
  <script src="../assets/js/jquery-3.3.1.min.js">
  </script>
  <script src="../assets/js/plyr.polyfilled.min.js">
  </script>
  <script src="../assets/js/bootstrap.min.js">
  </script>
  <script src="../assets/js/jquery.mCustomScrollbar.concat.min.js">
  </script>
  <script src="../assets/js/katex.min.js">
  </script>
  <script>
   // Initialize Plyr video players
    const players = Array.from(document.querySelectorAll('video')).map(p => new Plyr(p));

    // render math equations
    let elMath = document.getElementsByClassName('mathquill');
    for (let i = 0, len = elMath.length; i < len; i += 1) {
      const el = elMath[i];

      katex.render(el.textContent, el, {
        throwOnError: false
      });
    }

    // this hack will make sure Bootstrap tabs work when using Handlebars
    if ($('#question-tabs').length && $('#user-answer-tabs').length) {
      $("#question-tabs a.nav-link").on('click', function () {
        $("#question-tab-contents .tab-pane").hide();
        $($(this).attr("href")).show();
      });
      $("#user-answer-tabs a.nav-link").on('click', function () {
        $("#user-answer-tab-contents .tab-pane").hide();
        $($(this).attr("href")).show();
      });
    } else {
      $("a.nav-link").on('click', function () {
        $(".tab-pane").hide();
        $($(this).attr("href")).show();
      });
    }

    // side bar events
    $(document).ready(function () {
      $("#sidebar").mCustomScrollbar({
        theme: "minimal"
      });

      $('#sidebarCollapse').on('click', function () {
        $('#sidebar, #content').toggleClass('active');
        $('.collapse.in').toggleClass('in');
        $('a[aria-expanded=true]').attr('aria-expanded', 'false');
      });

      // scroll to first video on page loading
      if ($('video').length) {
        $('html,body').animate({ scrollTop: $('div.plyr').prev().offset().top});
      }

      // auto play first video: this may not work with chrome/safari due to autoplay policy
      if (players && players.length > 0) {
        players[0].play();
      }

      // scroll sidebar to current concept
      const currentInSideBar = $( "ul.sidebar-list.components li a:contains('03. Overview of the ND Program')" )
      currentInSideBar.css( "text-decoration", "underline" );
      $("#sidebar").mCustomScrollbar('scrollTo', currentInSideBar);
    });
  </script>
 </body>
</html>
