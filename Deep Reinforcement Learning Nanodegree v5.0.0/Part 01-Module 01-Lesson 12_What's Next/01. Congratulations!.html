<!-- udacimak v1.4.4 -->
<!DOCTYPE html>
<html lang="en">
 <head>
  <meta charset="utf-8"/>
  <meta content="width=device-width, initial-scale=1.0" name="viewport"/>
  <meta content="ie=edge" http-equiv="X-UA-Compatible"/>
  <title>
   Congratulations!
  </title>
  <link href="../assets/css/bootstrap.min.css" rel="stylesheet"/>
  <link href="../assets/css/plyr.css" rel="stylesheet"/>
  <link href="../assets/css/katex.min.css" rel="stylesheet"/>
  <link href="../assets/css/jquery.mCustomScrollbar.min.css" rel="stylesheet"/>
  <link href="../assets/css/styles.css" rel="stylesheet"/>
  <link href="../assets/img/udacimak.png" rel="shortcut icon" type="image/png">
  </link>
 </head>
 <body>
  <div class="wrapper">
   <nav id="sidebar">
    <div class="sidebar-header">
     <h3>
      What's Next?
     </h3>
    </div>
    <ul class="sidebar-list list-unstyled CTAs">
     <li>
      <a class="article" href="../index.html">
       Back to Home
      </a>
     </li>
    </ul>
    <ul class="sidebar-list list-unstyled components">
     <li class="">
      <a href="01. Congratulations!.html">
       01. Congratulations!
      </a>
     </li>
     <li class="">
      <a href="02. What can you do now.html">
       02. What can you do now?
      </a>
     </li>
    </ul>
    <ul class="sidebar-list list-unstyled CTAs">
     <li>
      <a class="article" href="../index.html">
       Back to Home
      </a>
     </li>
    </ul>
   </nav>
   <div id="content">
    <header class="container-fluild header">
     <div class="container">
      <div class="row">
       <div class="col-12">
        <div class="align-items-middle">
         <button class="btn btn-toggle-sidebar" id="sidebarCollapse" type="button">
          <div>
          </div>
          <div>
          </div>
          <div>
          </div>
         </button>
         <h1 style="display: inline-block">
          01. Congratulations!
         </h1>
        </div>
       </div>
      </div>
     </div>
    </header>
    <main class="container">
     <div class="row">
      <div class="col-12">
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <h1 id="congratulations">
          Congratulations!
         </h1>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <p>
          You have reached the end of the first part of the nanodegree and now have a strong foundational background in reinforcement learning.  You should be proud of all of your hard work!  Take the time to celebrate your accomplishment!
         </p>
         <p>
          Over the next couple of months, you will dive deeply into cutting-edge deep reinforcement learning and build much more!
         </p>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
         <p>
          Arpan Rollercoaster
         </p>
        </h3>
        <video controls="">
         <source src="01. Arpan Rollercoaster-Rf6cCYRqV58.mp4" type="video/mp4"/>
         <track default="true" kind="subtitles" label="en" src="01. Arpan Rollercoaster-Rf6cCYRqV58.en.vtt" srclang="en"/>
         <track default="false" kind="subtitles" label="CN" src="01. Arpan Rollercoaster-Rf6cCYRqV58.zh-CN.vtt" srclang="CN"/>
        </video>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <h2 id="-where-have-we-been">
          ### Where have we been?
         </h2>
         <p>
          In the first several lessons, you built a strong foundation in reinforcement learning, by learning how to solve finite Markov Decision Processes (MDPs) where the number of states and actions is limited.  For instance, you wrote your own implementations of many
          <strong>
           <em>
            tabular solution methods
           </em>
          </strong>
          such as
          <strong>
           Q-Learning
          </strong>
          and
          <strong>
           Expected Sarsa
          </strong>
          , among other algorithms.
         </p>
         <p>
          Then, you learned about how to generalize these algorithms to work with large and continuous spaces.  Using techniques such as
          <strong>
           tile coding
          </strong>
          and
          <strong>
           coarse coding
          </strong>
          , you can expand the size of the problems that can be solved with traditional reinforcement learning techniques.
         </p>
         <p>
          As you learned in the previous lesson, this lays the foundation for developing deep reinforcement learning algorithms.
         </p>
         <h2 id="-where-are-we-going">
          ### Where are we going?
         </h2>
         <p>
          <strong>
           Deep Reinforcement Learning
          </strong>
          is a relatively recent term that refers to approaches that use deep learning (mainly multi-layer neural networks) to solve reinforcement learning problems.
         </p>
         <p>
          In the next part of the nanodegree, you'll learn all about
          <strong>
           Value-Based Methods
          </strong>
          (such as the
          <strong>
           Deep Q-Learning
          </strong>
          algorithm) that use a neural network in place of the Q-table (estimated optimal action-value function) from traditional algorithms.
         </p>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <figure class="figure">
          <img alt="Visualization of Deep Q-Network (DQN) applied to Atari game. ([Source](https://leonardoaraujosantos.gitbooks.io/artificial-inteligence/content/deep_q_learning.html))" class="img img-fluid" src="img/dqn.png"/>
          <figcaption class="figure-caption">
           <p>
            Visualization of Deep Q-Network (DQN) applied to Atari game. (
            <a href="https://leonardoaraujosantos.gitbooks.io/artificial-inteligence/content/deep_q_learning.html" rel="noopener noreferrer" target="_blank">
             Source
            </a>
            )
           </p>
          </figcaption>
         </figure>
        </div>
       </div>
       <div class="divider">
       </div>
      </div>
      <div class="col-12">
       <p class="text-right">
        <a class="btn btn-outline-primary mt-4" href="02. What can you do now.html" role="button">
         Next Concept
        </a>
       </p>
      </div>
     </div>
    </main>
    <footer class="footer">
     <div class="container">
      <div class="row">
       <div class="col-12">
        <p class="text-center">
         udacity2.0 If you need the newest courses Plase add me wechat: udacity6
        </p>
       </div>
      </div>
     </div>
    </footer>
   </div>
  </div>
  <script src="../assets/js/jquery-3.3.1.min.js">
  </script>
  <script src="../assets/js/plyr.polyfilled.min.js">
  </script>
  <script src="../assets/js/bootstrap.min.js">
  </script>
  <script src="../assets/js/jquery.mCustomScrollbar.concat.min.js">
  </script>
  <script src="../assets/js/katex.min.js">
  </script>
  <script>
   // Initialize Plyr video players
    const players = Array.from(document.querySelectorAll('video')).map(p => new Plyr(p));

    // render math equations
    let elMath = document.getElementsByClassName('mathquill');
    for (let i = 0, len = elMath.length; i < len; i += 1) {
      const el = elMath[i];

      katex.render(el.textContent, el, {
        throwOnError: false
      });
    }

    // this hack will make sure Bootstrap tabs work when using Handlebars
    if ($('#question-tabs').length && $('#user-answer-tabs').length) {
      $("#question-tabs a.nav-link").on('click', function () {
        $("#question-tab-contents .tab-pane").hide();
        $($(this).attr("href")).show();
      });
      $("#user-answer-tabs a.nav-link").on('click', function () {
        $("#user-answer-tab-contents .tab-pane").hide();
        $($(this).attr("href")).show();
      });
    } else {
      $("a.nav-link").on('click', function () {
        $(".tab-pane").hide();
        $($(this).attr("href")).show();
      });
    }

    // side bar events
    $(document).ready(function () {
      $("#sidebar").mCustomScrollbar({
        theme: "minimal"
      });

      $('#sidebarCollapse').on('click', function () {
        $('#sidebar, #content').toggleClass('active');
        $('.collapse.in').toggleClass('in');
        $('a[aria-expanded=true]').attr('aria-expanded', 'false');
      });

      // scroll to first video on page loading
      if ($('video').length) {
        $('html,body').animate({ scrollTop: $('div.plyr').prev().offset().top});
      }

      // auto play first video: this may not work with chrome/safari due to autoplay policy
      if (players && players.length > 0) {
        players[0].play();
      }

      // scroll sidebar to current concept
      const currentInSideBar = $( "ul.sidebar-list.components li a:contains('01. Congratulations!')" )
      currentInSideBar.css( "text-decoration", "underline" );
      $("#sidebar").mCustomScrollbar('scrollTo', currentInSideBar);
    });
  </script>
 </body>
</html>
