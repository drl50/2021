<!-- udacimak v1.4.4 -->
<!DOCTYPE html>
<html lang="en">
 <head>
  <meta charset="utf-8"/>
  <meta content="width=device-width, initial-scale=1.0" name="viewport"/>
  <meta content="ie=edge" http-equiv="X-UA-Compatible"/>
  <title>
   MC Prediction - Part 3
  </title>
  <link href="../assets/css/bootstrap.min.css" rel="stylesheet"/>
  <link href="../assets/css/plyr.css" rel="stylesheet"/>
  <link href="../assets/css/katex.min.css" rel="stylesheet"/>
  <link href="../assets/css/jquery.mCustomScrollbar.min.css" rel="stylesheet"/>
  <link href="../assets/css/styles.css" rel="stylesheet"/>
  <link href="../assets/img/udacimak.png" rel="shortcut icon" type="image/png">
  </link>
 </head>
 <body>
  <div class="wrapper">
   <nav id="sidebar">
    <div class="sidebar-header">
     <h3>
      Monte Carlo Methods
     </h3>
    </div>
    <ul class="sidebar-list list-unstyled CTAs">
     <li>
      <a class="article" href="../index.html">
       Back to Home
      </a>
     </li>
    </ul>
    <ul class="sidebar-list list-unstyled components">
     <li class="">
      <a href="01. Review.html">
       01. Review
      </a>
     </li>
     <li class="">
      <a href="02. Gridworld Example.html">
       02. Gridworld Example
      </a>
     </li>
     <li class="">
      <a href="03. Monte Carlo Methods.html">
       03. Monte Carlo Methods
      </a>
     </li>
     <li class="">
      <a href="04. MC Prediction - Part 1.html">
       04. MC Prediction - Part 1
      </a>
     </li>
     <li class="">
      <a href="05. MC Prediction - Part 2.html">
       05. MC Prediction - Part 2
      </a>
     </li>
     <li class="">
      <a href="06. MC Prediction - Part 3.html">
       06. MC Prediction - Part 3
      </a>
     </li>
     <li class="">
      <a href="07. OpenAI Gym BlackJackEnv.html">
       07. OpenAI Gym: BlackJackEnv
      </a>
     </li>
     <li class="">
      <a href="08. Workspace - Introduction.html">
       08. Workspace - Introduction
      </a>
     </li>
     <li class="">
      <a href="09. Coding Exercise.html">
       09. Coding Exercise
      </a>
     </li>
     <li class="">
      <a href="10. Workspace.html">
       10. Workspace
      </a>
     </li>
     <li class="">
      <a href="11. Greedy Policies.html">
       11. Greedy Policies
      </a>
     </li>
     <li class="">
      <a href="12. Epsilon-Greedy Policies.html">
       12. Epsilon-Greedy Policies
      </a>
     </li>
     <li class="">
      <a href="13. MC Control.html">
       13. MC Control
      </a>
     </li>
     <li class="">
      <a href="14. Exploration vs. Exploitation.html">
       14. Exploration vs. Exploitation
      </a>
     </li>
     <li class="">
      <a href="15. Incremental Mean.html">
       15. Incremental Mean
      </a>
     </li>
     <li class="">
      <a href="16. Constant-alpha.html">
       16. Constant-alpha
      </a>
     </li>
     <li class="">
      <a href="17. Coding Exercise.html">
       17. Coding Exercise
      </a>
     </li>
     <li class="">
      <a href="18. Workspace.html">
       18. Workspace
      </a>
     </li>
     <li class="">
      <a href="19. Summary.html">
       19. Summary
      </a>
     </li>
    </ul>
    <ul class="sidebar-list list-unstyled CTAs">
     <li>
      <a class="article" href="../index.html">
       Back to Home
      </a>
     </li>
    </ul>
   </nav>
   <div id="content">
    <header class="container-fluild header">
     <div class="container">
      <div class="row">
       <div class="col-12">
        <div class="align-items-middle">
         <button class="btn btn-toggle-sidebar" id="sidebarCollapse" type="button">
          <div>
          </div>
          <div>
          </div>
          <div>
          </div>
         </button>
         <h1 style="display: inline-block">
          06. MC Prediction - Part 3
         </h1>
        </div>
       </div>
      </div>
     </div>
    </header>
    <main class="container">
     <div class="row">
      <div class="col-12">
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <h1 id="mc-prediction">
          MC Prediction
         </h1>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <figure class="figure">
          <img alt="" class="img img-fluid" src="img/screen-shot-2018-04-30-at-10.27.56-am.png"/>
          <figcaption class="figure-caption">
          </figcaption>
         </figure>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <p>
          So far in this lesson, we have discussed how the agent can take a bad policy, like the equiprobable random policy, use it to collect some episodes, and then consolidate the results to arrive at a better policy.
         </p>
         <p>
          In the video in the previous concept, you saw that estimating the action-value function with a Q-table is an important intermediate step.  We also refer to this as the
          <strong>
           prediction problem
          </strong>
          .
         </p>
         <blockquote>
          <p>
           <strong>
            Prediction Problem
           </strong>
           : Given a policy, how might the agent estimate the value function for that policy?
          </p>
         </blockquote>
         <p>
          We've been specifically interested in the action-value function, but the
          <strong>
           prediction problem
          </strong>
          also refers to approaches that can be used to estimate the state-value function.  We refer to Monte Carlo (MC) approaches to the prediction problem as
          <strong>
           MC prediction methods
          </strong>
          .
         </p>
         <h2 id="-pseudocode">
          ## Pseudocode
         </h2>
         <p>
          As you have learned in the videos, in the algorithm for MC prediction, we begin by collecting many episodes with the policy.  Then, we note that each entry in the Q-table corresponds to a particular state and action.  To populate an entry, we use the return that followed when the agent was in that state, and chose the action.  In the event that the agent has selected the same action many times from the same state, we need only average the returns.
         </p>
         <p>
          Before we dig into the pseudocode, we note that there are two different versions of MC prediction, depending on how you decide to treat the special case where -
          <em>
           in a single episode
          </em>
          - the same action is selected from the same state many times.  For more information, watch the video below.
         </p>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
         <p>
          L606 MC Prediction Part 3 RENDERv1 V4
         </p>
        </h3>
        <video controls="">
         <source src="06. L606 MC Prediction Part 3 RENDERv1 V4-9LP6uXdmWxQ.mp4" type="video/mp4"/>
         <track default="true" kind="subtitles" label="en" src="06. L606 MC Prediction Part 3 RENDERv1 V4-9LP6uXdmWxQ.en.vtt" srclang="en"/>
        </video>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <p>
          As discussed in the video, we define every occurrence of a state in an episode as a
          <strong>
           visit
          </strong>
          to that state-action pair.  And, in the event that a state-action pair is visited more than once in an episode, we have two options.
         </p>
         <h4 id="option-1-every-visit-mc-prediction">
          Option 1: Every-visit MC Prediction
         </h4>
         <p>
          Average the returns following all visits to each state-action pair, in all episodes.
         </p>
         <h4 id="option-2-first-visit-mc-prediction">
          Option 2: First-visit MC Prediction
         </h4>
         <p>
          For each episode, we only consider the first visit to the state-action pair.  The pseudocode for this option can be found below.
         </p>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <figure class="figure">
          <img alt="" class="img img-fluid" src="img/screen-shot-2018-05-04-at-2.51.59-pm.png"/>
          <figcaption class="figure-caption">
          </figcaption>
         </figure>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <p>
          Don't let this pseudocode scare you!  The main idea is quite simple.  There are three relevant tables:
         </p>
         <ul>
          <li>
           <span class="mathquill ud-math">
            Q
           </span>
           - Q-table, with a row for each state and a column for each action.  The entry corresponding to state
           <span class="mathquill ud-math">
            s
           </span>
           and action
           <span class="mathquill ud-math">
            a
           </span>
           is denoted
           <span class="mathquill ud-math">
            Q(s,a)
           </span>
           .
          </li>
          <li>
           <span class="mathquill ud-math">
            N
           </span>
           - table that keeps track of the number of first visits we have made to each state-action pair.
          </li>
          <li>
           <span class="mathquill ud-math">
            returns_sum
           </span>
           - table that keeps track of the sum of the rewards obtained after first visits to each state-action pair.
          </li>
         </ul>
         <p>
          In the algorithm, the number of episodes the agent collects is equal to
          <span class="mathquill ud-math">
           num_episodes
          </span>
          .  After each episode,
          <span class="mathquill ud-math">
           N
          </span>
          and
          <span class="mathquill ud-math">
           returns_sum
          </span>
          are updated to store the information contained in the episode.  Then, after all of the episodes have been collected and the values in
          <span class="mathquill ud-math">
           N
          </span>
          and
          <span class="mathquill ud-math">
           returns_sum
          </span>
          have been finalized, we quickly obtain the final estimate for
          <span class="mathquill ud-math">
           Q
          </span>
          .
         </p>
         <p>
          Soon, you'll have the chance to implement this algorithm yourself!
         </p>
         <p>
          You will apply your code to OpenAI Gym's BlackJack environment.  Note that in the game of BlackJack, first-visit and every-visit MC return identical results!
         </p>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <h2 id="-first-visit-or-every-visit">
          ## First-visit or Every-visit?
         </h2>
         <p>
          Both the first-visit and every-visit method are
          <strong>
           guaranteed to converge
          </strong>
          to the true action-value function, as the number of visits to each state-action pair approaches infinity.  (
          <em>
           So, in other words, as long as the agent gets enough experience with each state-action pair, the value function estimate will be pretty close to the true value.
          </em>
          )  In the case of first-visit MC, convergence follows from the
          <a href="https://en.wikipedia.org/wiki/Law_of_large_numbers" rel="noopener noreferrer" target="_blank">
           Law of Large Numbers
          </a>
          , and the details are covered in section 5.1 of the
          <a href="http://go.udacity.com/rl-textbook" rel="noopener noreferrer" target="_blank">
           textbook
          </a>
          .
         </p>
         <p>
          If you are interested in learning more about the difference between first-visit and every-visit MC methods, you are encouraged to read Section 3 of [this paper](
          <a href="http://www-anw.cs.umass.edu/legacy/pubs/1995_96/singh_s_ML96.pdf" rel="noopener noreferrer" target="_blank">
           http://www-anw.cs.umass.edu/legacy/pubs/1995_96/singh_s_ML96.pdf
          </a>
          <br/>
          ).  The results are summarized in Section 3.6.  The authors show:
         </p>
         <ul>
          <li>
           Every-visit MC is
           <a href="https://en.wikipedia.org/wiki/Bias_of_an_estimator" rel="noopener noreferrer" target="_blank">
            biased
           </a>
           , whereas first-visit MC is unbiased (see Theorems 6 and 7).
          </li>
          <li>
           Initially, every-visit MC has lower
           <a href="https://en.wikipedia.org/wiki/Mean_squared_error" rel="noopener noreferrer" target="_blank">
            mean squared error (MSE)
           </a>
           , but as more episodes are collected, first-visit MC attains better MSE (see Corollary 9a and 10a, and Figure 4).
          </li>
         </ul>
        </div>
       </div>
       <div class="divider">
       </div>
      </div>
      <div class="col-12">
       <p class="text-right">
        <a class="btn btn-outline-primary mt-4" href="07. OpenAI Gym BlackJackEnv.html" role="button">
         Next Concept
        </a>
       </p>
      </div>
     </div>
    </main>
    <footer class="footer">
     <div class="container">
      <div class="row">
       <div class="col-12">
        <p class="text-center">
         udacity2.0 If you need the newest courses Plase add me wechat: udacity6
        </p>
       </div>
      </div>
     </div>
    </footer>
   </div>
  </div>
  <script src="../assets/js/jquery-3.3.1.min.js">
  </script>
  <script src="../assets/js/plyr.polyfilled.min.js">
  </script>
  <script src="../assets/js/bootstrap.min.js">
  </script>
  <script src="../assets/js/jquery.mCustomScrollbar.concat.min.js">
  </script>
  <script src="../assets/js/katex.min.js">
  </script>
  <script>
   // Initialize Plyr video players
    const players = Array.from(document.querySelectorAll('video')).map(p => new Plyr(p));

    // render math equations
    let elMath = document.getElementsByClassName('mathquill');
    for (let i = 0, len = elMath.length; i < len; i += 1) {
      const el = elMath[i];

      katex.render(el.textContent, el, {
        throwOnError: false
      });
    }

    // this hack will make sure Bootstrap tabs work when using Handlebars
    if ($('#question-tabs').length && $('#user-answer-tabs').length) {
      $("#question-tabs a.nav-link").on('click', function () {
        $("#question-tab-contents .tab-pane").hide();
        $($(this).attr("href")).show();
      });
      $("#user-answer-tabs a.nav-link").on('click', function () {
        $("#user-answer-tab-contents .tab-pane").hide();
        $($(this).attr("href")).show();
      });
    } else {
      $("a.nav-link").on('click', function () {
        $(".tab-pane").hide();
        $($(this).attr("href")).show();
      });
    }

    // side bar events
    $(document).ready(function () {
      $("#sidebar").mCustomScrollbar({
        theme: "minimal"
      });

      $('#sidebarCollapse').on('click', function () {
        $('#sidebar, #content').toggleClass('active');
        $('.collapse.in').toggleClass('in');
        $('a[aria-expanded=true]').attr('aria-expanded', 'false');
      });

      // scroll to first video on page loading
      if ($('video').length) {
        $('html,body').animate({ scrollTop: $('div.plyr').prev().offset().top});
      }

      // auto play first video: this may not work with chrome/safari due to autoplay policy
      if (players && players.length > 0) {
        players[0].play();
      }

      // scroll sidebar to current concept
      const currentInSideBar = $( "ul.sidebar-list.components li a:contains('06. MC Prediction - Part 3')" )
      currentInSideBar.css( "text-decoration", "underline" );
      $("#sidebar").mCustomScrollbar('scrollTo', currentInSideBar);
    });
  </script>
 </body>
</html>
