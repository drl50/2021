WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:03.480
Before moving on, let's talk a little bit more about what

00:00:03.480 --> 00:00:06.625
we just did and how it's related to supervised learning.

00:00:06.625 --> 00:00:08.789
As we discussed in the previous video,

00:00:08.789 --> 00:00:11.574
we begin by playing the game for an episode.

00:00:11.574 --> 00:00:17.174
If we make it to the other end of the street safely and in time, then we win the game.

00:00:17.175 --> 00:00:19.875
Then for each state action pair in the episode,

00:00:19.875 --> 00:00:23.280
we modify the network just a little bit to make it slightly more

00:00:23.280 --> 00:00:27.220
likely to select that action when it encounters the corresponding state.

00:00:27.219 --> 00:00:28.855
The idea was that,

00:00:28.855 --> 00:00:30.490
well if we won,

00:00:30.489 --> 00:00:34.524
those must have been good actions to select from there corresponding states.

00:00:34.524 --> 00:00:36.199
So let's modify the network,

00:00:36.200 --> 00:00:41.245
to reflect that by making it more likely to experience like gameplay in the future.

00:00:41.244 --> 00:00:46.054
So remember, how we use supervised learning for image classification.

00:00:46.054 --> 00:00:50.630
We have a data set of images along with their corresponding labels.

00:00:50.630 --> 00:00:56.640
And if we want to train a neural network to predict the label corresponding to any image.

00:00:56.640 --> 00:01:00.509
What we do is pass that image through the network to get a prediction.

00:01:00.509 --> 00:01:02.574
If the prediction is incorrect,

00:01:02.575 --> 00:01:04.730
we change the network weights just a little

00:01:04.730 --> 00:01:08.385
bit so that the prediction is slightly more correct.

00:01:08.385 --> 00:01:09.920
And if it's correct,

00:01:09.920 --> 00:01:13.100
we also nudge the weights again just a little bit,

00:01:13.099 --> 00:01:16.439
so that the network is more certain of the correct label.

00:01:16.439 --> 00:01:19.810
And we just loop over the dataset until eventually,

00:01:19.810 --> 00:01:22.189
the neural network gets as close as possible

00:01:22.189 --> 00:01:25.209
to giving us accurate predictions for each image.

00:01:25.209 --> 00:01:29.604
Now this is really similar to what we described with reinforcement learning.

00:01:29.605 --> 00:01:32.000
Namely, each has a dataset of

00:01:32.000 --> 00:01:36.140
input output pairs that we'll use to train the corresponding networks.

00:01:36.140 --> 00:01:39.995
One important difference is that when we do image classification.

00:01:39.995 --> 00:01:43.710
Typically we work with the dataset that doesn't change over time.

00:01:43.709 --> 00:01:47.494
So for instance, we download the image net data set once,

00:01:47.495 --> 00:01:50.750
and then we just pull random batches to train the network.

00:01:50.750 --> 00:01:53.599
However, in this reinforcement learning setting.

00:01:53.599 --> 00:01:56.179
The dataset varies by episode.

00:01:56.180 --> 00:01:59.765
So we use the policy to collect an episode,

00:01:59.765 --> 00:02:04.689
that gives us a Dataset or a bunch of matched state action pairs,

00:02:04.689 --> 00:02:09.129
and then we use that data set once to do a batch of updates.

00:02:09.129 --> 00:02:10.894
After those updates are done,

00:02:10.895 --> 00:02:13.340
we'll discard the dataset and then collect

00:02:13.340 --> 00:02:17.310
another episode which gives us another dataset and so on.

00:02:17.310 --> 00:02:20.384
So the dataset changes pretty frequently.

00:02:20.384 --> 00:02:25.789
And furthermore, it's highly likely that we will experience a situation where

00:02:25.789 --> 00:02:28.849
the dataset has multiple conflicting opinions

00:02:28.849 --> 00:02:31.909
about what the best output should be for an input,

00:02:31.909 --> 00:02:35.819
or in other words, what the best action is to take from a game state.

00:02:35.819 --> 00:02:38.489
The equivalent for image classification,

00:02:38.490 --> 00:02:41.855
would be of the same image appeared twice in the dataset.

00:02:41.854 --> 00:02:45.185
Where one entry said the image was of a dog,

00:02:45.185 --> 00:02:48.295
and the other entry said the image contained a cat.

00:02:48.294 --> 00:02:52.304
This is something that we won't encounter with image classification,

00:02:52.305 --> 00:02:55.724
and it does make our current situation more complex.

00:02:55.724 --> 00:02:59.169
But also I think more interesting.

