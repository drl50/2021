WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:02.129
Starting with a state,

00:00:02.129 --> 00:00:06.360
we learned previously how to search systematically through

00:00:06.360 --> 00:00:11.155
one layer of a game tree using the variables U,

00:00:11.154 --> 00:00:15.449
N, and V. Can we generalize this to go deeper into

00:00:15.449 --> 00:00:20.515
the tree so that we can better anticipate a long sequence of moves?

00:00:20.515 --> 00:00:26.469
This is possible through what's called expansion and back-propagation.

00:00:26.469 --> 00:00:28.884
Let's see how it works in action.

00:00:28.885 --> 00:00:33.890
First, we choose an action that maximizes U. U is zero,

00:00:33.890 --> 00:00:36.825
so we randomly choose an action.

00:00:36.825 --> 00:00:41.555
We play a random game and this time to current player one.

00:00:41.554 --> 00:00:44.320
So, we update V to one,

00:00:44.320 --> 00:00:47.085
and the visit count to one.

00:00:47.085 --> 00:00:52.759
Afterward, the total number of gameplay needs to be updated as well.

00:00:52.859 --> 00:01:01.450
Then, all the U values in all the branches will need to be updated like this.

00:01:01.450 --> 00:01:03.840
For the next iteration,

00:01:03.840 --> 00:01:06.865
we choose the branch with the maximum U,

00:01:06.864 --> 00:01:09.074
1.5 in this case.

00:01:09.075 --> 00:01:14.090
This time, the node has already been visited previously and we

00:01:14.090 --> 00:01:19.219
would like to get some more information by exploring deeper into the tree structure.

00:01:19.219 --> 00:01:22.789
So, instead of just playing another random game,

00:01:22.790 --> 00:01:26.460
we consider all the possible next moves.

00:01:27.909 --> 00:01:33.234
All the expanded nodes come with their own variables U, N,

00:01:33.234 --> 00:01:37.605
and V. Again, we choose the action with the maximum U,

00:01:37.605 --> 00:01:39.750
they're all zero in this case.

00:01:39.750 --> 00:01:43.840
So, we randomly choose an action and play a random game.

00:01:43.840 --> 00:01:46.674
This time, the blue player won.

00:01:46.674 --> 00:01:50.084
So we update V and N. Now,

00:01:50.084 --> 00:01:54.405
the total number of visits for this cluster of nodes has been updated,

00:01:54.405 --> 00:01:57.030
so we need to update N total to one.

00:01:57.030 --> 00:02:02.984
This changes U for all the branches and so we need to update them.

00:02:02.984 --> 00:02:06.829
After all the second level nodes are up to date,

00:02:06.829 --> 00:02:08.930
we need to update the statistics on

00:02:08.930 --> 00:02:13.545
the previous node this procedure is called back-propagation,

00:02:13.544 --> 00:02:17.914
where we go back up the tree to update all the variables.

00:02:17.914 --> 00:02:20.620
First, the total number of visits,

00:02:20.620 --> 00:02:22.670
N, needs to be increased.

00:02:22.669 --> 00:02:25.239
Second, the expected outcome,

00:02:25.240 --> 00:02:27.290
V, needs to be updated.

00:02:27.289 --> 00:02:32.269
We replace it by the average outcome of all the games that are played from

00:02:32.270 --> 00:02:37.770
this node keeping in mind that the outcome is from the perspective of the current player,

00:02:37.770 --> 00:02:39.735
orange in this case.

00:02:39.735 --> 00:02:42.090
This gives N equals two,

00:02:42.090 --> 00:02:43.900
and V equals zero.

00:02:43.900 --> 00:02:45.905
Because in the previous play out,

00:02:45.905 --> 00:02:48.229
the blue player won.

00:02:48.280 --> 00:02:51.300
With the increase visit counts,

00:02:51.300 --> 00:02:54.875
N total needs to be updated as well,

00:02:54.875 --> 00:02:59.449
and then all the Us also needs to be updated.

00:02:59.479 --> 00:03:03.019
Now, we can repeat this process again and

00:03:03.020 --> 00:03:07.145
again until a fixed number of total games are played.

00:03:07.145 --> 00:03:10.480
We might get something like this for example.

00:03:10.509 --> 00:03:13.134
Then to choose the next move,

00:03:13.134 --> 00:03:16.504
we pick the node with the highest visit count,

00:03:16.504 --> 00:03:18.849
21 in this case.

00:03:18.849 --> 00:03:23.979
One advantage of expansion and propagation is that if we

00:03:23.979 --> 00:03:28.884
want to utilize Monte Carlo tree search again after making a move,

00:03:28.884 --> 00:03:31.344
we don't need to start from scratch.

00:03:31.344 --> 00:03:35.020
As we can reuse previous results by replacing

00:03:35.020 --> 00:03:39.630
the top node with the chosen node for the next move like this,

00:03:39.629 --> 00:03:44.079
and we can continue our Monte Carlo tree search.

00:03:44.219 --> 00:03:50.810
So, that's it. We can finally summarize the Monte Carlo tree search algorithm.

00:03:50.900 --> 00:03:54.265
First, we initialize the top node,

00:03:54.264 --> 00:03:59.569
then we loop over N total times the following search procedure.

00:03:59.569 --> 00:04:01.689
Starting from the top node,

00:04:01.689 --> 00:04:04.099
which reverse to gain tree as far as

00:04:04.099 --> 00:04:09.435
possible by repeatedly going into the child node with the largest U.

00:04:09.435 --> 00:04:13.020
Next, if the node hasn't been visited yet,

00:04:13.020 --> 00:04:14.955
we play a random game.

00:04:14.955 --> 00:04:21.805
Otherwise, we expand the node and play a game from one of the child node randomly.

00:04:21.805 --> 00:04:28.430
Next, we update statistics on that node based on the outcome of the gameplay.

00:04:28.430 --> 00:04:34.355
We also back-propagate the results to the parent nodes and update visit counts,

00:04:34.355 --> 00:04:37.425
and the dual variables if necessary.

00:04:37.425 --> 00:04:39.814
After the iteration is done,

00:04:39.814 --> 00:04:46.375
we simply pick the move with the highest visit counts. So, that's it.

00:04:46.375 --> 00:04:49.865
This summarizes how can choose a move.

00:04:49.865 --> 00:04:53.405
Using Monte Carlo tree search on a zero-sum game.

00:04:53.404 --> 00:04:58.639
Generally speaking, the more random games we play during the search,

00:04:58.639 --> 00:05:04.279
the deeper we will search in the tree and the better the resulting moves will be.

