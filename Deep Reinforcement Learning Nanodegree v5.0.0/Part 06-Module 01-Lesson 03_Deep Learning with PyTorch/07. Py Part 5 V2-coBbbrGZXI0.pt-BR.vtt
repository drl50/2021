WEBVTT
Kind: captions
Language: pt-BR

00:00:00.135 --> 00:00:02.005
Olá, bem-vindo de volta.

00:00:02.038 --> 00:00:03.650
Neste vídeo e notebook,

00:00:03.683 --> 00:00:06.772
vou falar de inferência
e validação.

00:00:06.805 --> 00:00:09.662
Inferência é quando temos
uma topologia em árvore

00:00:09.695 --> 00:00:12.749
e a usamos
para fazer predições.

00:00:12.782 --> 00:00:14.749
Redes neurais têm um problema,

00:00:14.782 --> 00:00:17.345
que é uma tendência de ter
uma performance muito boa

00:00:17.378 --> 00:00:18.929
nos dados de treinamento

00:00:18.962 --> 00:00:21.741
e não conseguir generalizar
para outros dados.

00:00:21.774 --> 00:00:24.350
Por exemplo, se você trocasse
um monte de imagens

00:00:24.383 --> 00:00:27.240
e atribuísse uma imagem
que não tivesse sido vista antes,

00:00:27.273 --> 00:00:30.952
ela faria um péssimo trabalho
ao predizer o que está na imagem.

00:00:30.985 --> 00:00:34.626
Redes neurais aprendem demais
com os dados de treinamento

00:00:34.659 --> 00:00:38.092
e são ruins em generalizar,
fazendo um sobreajuste.

00:00:38.125 --> 00:00:40.841
No teste de sobreajuste
durante o treinamento,

00:00:40.874 --> 00:00:43.292
realizamos uma inferência
com nossa rede

00:00:43.325 --> 00:00:46.541
em um conjunto de teste
ou no nosso conjunto de validação.

00:00:46.574 --> 00:00:49.442
Este conjunto de dados se parece
com os dados de treinamento,

00:00:49.475 --> 00:00:51.248
mas não está
no conjunto de treinamento.

00:00:51.281 --> 00:00:54.506
Basicamente, a rede neural
ainda não viu esses dados.

00:00:54.539 --> 00:00:57.862
Assim, ao fazermos o teste
neste conjunto de validação,

00:00:57.895 --> 00:01:01.260
podemos ver o quanto a rede
é capaz de generalizar

00:01:01.293 --> 00:01:04.907
os dados que ela
ainda não viu.

00:01:04.940 --> 00:01:09.211
Para começar,
vou importar pacotes,

00:01:09.244 --> 00:01:12.050
como PyTorch e torchvision,
como sempre.

00:01:12.083 --> 00:01:16.179
Aqui, novamente, carrego
o conjunto de dados Fashion-MNIST.

00:01:16.212 --> 00:01:18.985
Veja que estou delegando aqui
os dados de teste,

00:01:19.018 --> 00:01:23.135
então esses serão os dados
que usaremos para validação.

00:01:23.168 --> 00:01:25.714
Temos os dados,
os dados de treinamento

00:01:25.747 --> 00:01:28.031
que vamos pegar
de trainset e trainloader

00:01:28.064 --> 00:01:31.270
e temos os dados
de validação de teste de testloader.

00:01:31.303 --> 00:01:34.454
Aqui eu construí uma rede
um pouco mais avançada

00:01:34.487 --> 00:01:37.861
do que a que mostrei até agora
porque queria ter

00:01:37.894 --> 00:01:40.399
um número arbitrário
de camadas ocultas.

00:01:40.432 --> 00:01:43.222
Basicamente, eu queria passar
uma lista como essa,

00:01:43.255 --> 00:01:46.027
e ela automaticamente iria construir
3 camadas ocultas

00:01:46.060 --> 00:01:48.894
com este número de unidades
em cada uma dessas camadas.

00:01:49.261 --> 00:01:53.092
Para isso, usei nn.ModuleList.

00:01:53.125 --> 00:01:56.279
A ideia é que ela funcione
como uma lista normal

00:01:56.312 --> 00:01:59.494
em que você possa adicionar coisas,
aumentá-la, e assim por diante.

00:01:59.527 --> 00:02:04.832
Mas o modelo consegue fazer
um PyTorch em modelos,

00:02:04.865 --> 00:02:08.311
rastrear os módulos que você
está adicionando à lista de módulos.

00:02:08.344 --> 00:02:10.442
Porque, se você usasse
uma lista normal,

00:02:10.475 --> 00:02:12.605
o PyTorch não conseguiria
rastrear isso,

00:02:12.638 --> 00:02:17.682
e você não veria esses módulos
e operações no seu modelo.

00:02:17.715 --> 00:02:19.817
Não vou falar muito
sobre como isso funciona

00:02:19.850 --> 00:02:21.890
porque escrevi aqui.

00:02:21.923 --> 00:02:24.975
Portanto, fique à vontade
para ler quando quiser.

00:02:25.008 --> 00:02:29.794
As coisas mais importantes
que você deve notar nessa nova rede

00:02:29.827 --> 00:02:32.208
é que adicionei um dropout.

00:02:32.241 --> 00:02:34.221
Como visto antes,

00:02:34.254 --> 00:02:38.425
o dropout apaga aleatoriamente
algumas dessas conexões

00:02:38.458 --> 00:02:41.919
entre as camadas, à medida
que a rede vai treinando.

00:02:41.952 --> 00:02:45.068
Isso acaba forçando
unidades na rede

00:02:45.101 --> 00:02:49.688
a aprender vários recursos
dos dados de input,

00:02:49.721 --> 00:02:52.938
e isso ajuda a rede
a generalizar.

00:02:52.971 --> 00:02:56.814
Para usar o dropout,
você apenas cria esta operação,

00:02:56.847 --> 00:02:58.977
este módulo,
como você faria normalmente,

00:02:59.010 --> 00:03:03.283
e dá a ela uma probabilidade
de largar unidades.

00:03:03.316 --> 00:03:05.967
Podemos adicionar o dropout
e o passo adiante,

00:03:06.000 --> 00:03:10.112
como faríamos
com outros módulos e operações.

00:03:10.145 --> 00:03:12.995
Portanto, self.dropout,
e passamos um tensor.

00:03:13.028 --> 00:03:15.321
A segunda coisa
que você deve notar

00:03:15.354 --> 00:03:20.202
é que estou retornando
log_softmax do passo adiante.

00:03:20.235 --> 00:03:22.747
Estou fazendo isso
porque softmax retorna

00:03:22.780 --> 00:03:24.424
uma distribuição
de probabilidade,

00:03:24.457 --> 00:03:26.306
então o problema
é que, muitas vezes,

00:03:26.339 --> 00:03:30.634
você vai conseguir resultados
muito próximos a 0 ou a 1.

00:03:30.667 --> 00:03:35.398
Por conta da imprecisão
em representar números

00:03:35.431 --> 00:03:37.150
como pontos flutuantes,

00:03:37.183 --> 00:03:41.075
isso pode causar
instabilidades em cálculos

00:03:41.108 --> 00:03:45.658
e, em geral, pode gerar
muitas imprecisões.

00:03:45.691 --> 00:03:49.252
Para resolver isso,
pegamos o log de softmax,

00:03:49.285 --> 00:03:52.604
e isso afasta os números
de 0 e de 1

00:03:52.637 --> 00:03:57.201
e aproxima de números
normais negativos, como -4.

00:03:57.234 --> 00:04:00.894
Isso ajuda a manter
a contagem estável,

00:04:00.927 --> 00:04:02.716
ajuda na precisão

00:04:02.749 --> 00:04:05.975
e, em geral,
é bem mais fácil de se trabalhar

00:04:06.008 --> 00:04:09.241
no espaço logarítmico
de funções de probabilidade.

00:04:09.274 --> 00:04:11.777
Aqui estou criando o modelo
como faço normalmente,

00:04:11.810 --> 00:04:13.987
784 unidades,
como unidades de input,

00:04:14.020 --> 00:04:15.537
10 de output,

00:04:15.570 --> 00:04:16.695
duas camadas ocultas,

00:04:16.728 --> 00:04:19.607
uma de 516 unidades
e outra com 256 unidades,

00:04:19.640 --> 00:04:22.746
e minha probabilidade
de dropout como 0,5.

00:04:23.654 --> 00:04:27.690
Como estou usando log_softmax
como meu output,

00:04:27.723 --> 00:04:31.238
devo usar a perda de verossimilhança
logarítmica negativa,

00:04:31.271 --> 00:04:33.591
então uso isso aqui,
esse é o meu critério.

00:04:33.624 --> 00:04:37.332
É igual à perda de entropia cruzada
que você viu antes,

00:04:37.365 --> 00:04:44.362
que log_softmax seja o input.

00:04:44.395 --> 00:04:46.667
Como também estou usando
o otimizador Adam,

00:04:46.700 --> 00:04:48.511
e, como disse anteriormente,

00:04:48.544 --> 00:04:51.958
esta é uma variação do gradiente
descendente estocástico

00:04:51.991 --> 00:04:53.487
que usa o momentum

00:04:53.520 --> 00:04:55.612
e acaba treinando
suas redes mais rápido

00:04:55.645 --> 00:04:58.719
do que com um gradiente
descendente estocástico normal.

00:04:58.752 --> 00:05:03.370
Agora vou mostrar como escrever
este código de validação.

00:05:03.403 --> 00:05:06.919
A ideia do código de validação
com o passo de validação

00:05:06.952 --> 00:05:12.142
é pegar os dados
do conjunto de dados de teste,

00:05:12.175 --> 00:05:14.481
rodá-los na nossa rede,

00:05:14.514 --> 00:05:18.916
medir a perda dos dados de teste
e também a acurácia.

00:05:18.949 --> 00:05:23.661
Ou seja, como a rede está lidando
com os dados que ainda não viu.

00:05:23.955 --> 00:05:29.520
Normal, começamos pegando
imagens, rótulos...

00:05:30.188 --> 00:05:31.934
Dessa vez, vamos pegar
do testloader

00:05:31.967 --> 00:05:34.849
em vez do trainloader,
pois são imagens de teste.

00:05:35.354 --> 00:05:38.035
Damos formas às imagens

00:05:38.068 --> 00:05:41.604
e passamos as imagens
pela rede.

00:05:41.637 --> 00:05:45.286
Novamente, essas imagens estão vindo
do conjunto de teste,

00:05:45.319 --> 00:05:48.770
e vamos obter o output
do conjunto de teste.

00:05:48.803 --> 00:05:54.481
Podemos atualizar para registrar
perda de teste.

00:05:54.514 --> 00:05:56.187
Critério...

00:05:57.279 --> 00:06:00.805
Não estamos interessados em fazer
uma retropropagação com esta perda,

00:06:00.838 --> 00:06:04.110
apenas queremos medir a perda
do conjunto de dados de teste.

00:06:04.143 --> 00:06:07.715
É assim que medimos a perda,
mas também quero medir a acurácia,

00:06:07.748 --> 00:06:11.345
se a rede está predizendo
o rótulo correto

00:06:11.378 --> 00:06:13.691
para o conjunto de dados
de teste.

00:06:14.460 --> 00:06:19.549
Aqui, como sempre,
vou calcular nossas probabilidades.

00:06:19.582 --> 00:06:22.500
Portanto, torch.exponential...

00:06:22.533 --> 00:06:24.849
Novamente,
nosso output é log_softmax.

00:06:24.882 --> 00:06:27.006
O inverso de log
é exponencial,

00:06:27.039 --> 00:06:31.035
então isso vai nos dar
a distribuição de softmax.

00:06:31.068 --> 00:06:33.577
Isso deve funcionar até agora.
Legal.

00:06:33.610 --> 00:06:36.501
Essas são as probabilidades,
vamos verificá-las.

00:06:36.534 --> 00:06:37.638
Legal.

00:06:37.671 --> 00:06:39.253
Elas têm...

00:06:40.107 --> 00:06:42.252
É, 64 por 10.

00:06:42.285 --> 00:06:46.297
Quero ver se nossa rede
está predizendo o rótulo correto.

00:06:46.330 --> 00:06:50.216
Preciso comparar o rótulo correto
com o que a rede está predizendo.

00:06:50.249 --> 00:06:52.121
Para obter o que a rede
está predizendo,

00:06:52.154 --> 00:06:56.401
preciso pegar a maior probabilidade
do output de softmax.

00:06:57.401 --> 00:06:59.704
É ps.max...

00:07:00.615 --> 00:07:02.961
Quero pegar
a primeira dimensão.

00:07:02.994 --> 00:07:05.378
Por aqui, 10.

00:07:05.936 --> 00:07:09.084
Isso me dá
dois tensores diferentes.

00:07:09.117 --> 00:07:12.946
O primeiro tensor
são as probabilidades em si,

00:07:12.979 --> 00:07:18.211
as maiores probabilidades
e, no segundo tensor,

00:07:18.244 --> 00:07:22.223
é o índice
da maior probabilidade.

00:07:22.256 --> 00:07:24.395
Este índice é interessante,

00:07:24.428 --> 00:07:26.997
porque ele, na verdade,
está nos dizendo

00:07:27.030 --> 00:07:31.311
que classe tem a maior probabilidade
no output de softmax.

00:07:31.344 --> 00:07:34.333
Como o segundo tensor,
esse cara aqui

00:07:34.366 --> 00:07:36.599
está nos mostrando
as classes preditas.

00:07:36.632 --> 00:07:39.409
Então vou fazer de 1.
E isso nos dará as classes preditas.

00:07:39.442 --> 00:07:43.955
E depois teremos que comparar isso
com nossos rótulos verdadeiros.

00:07:44.296 --> 00:07:47.475
Vou chamar isso de "equality".

00:07:47.508 --> 00:07:51.675
Vamos ver como está.
Equality.

00:07:51.708 --> 00:07:55.586
Aqui temos um outro tensor,

00:07:55.619 --> 00:07:58.356
em que 1 quer dizer
que fizemos a predição correta,

00:07:58.389 --> 00:08:00.897
e 0 que fizemos
a predição incorreta.

00:08:01.243 --> 00:08:03.423
Para medir a acurácia...

00:08:03.456 --> 00:08:05.724
Novamente,
a acurácia é basicamente

00:08:05.757 --> 00:08:08.569
quantas vezes ele fez
a predição corretamente

00:08:08.602 --> 00:08:11.889
de todas as predições que fez.

00:08:11.922 --> 00:08:13.546
Como são 1 e 0,

00:08:13.579 --> 00:08:17.026
apenas precisamos somar
as corretas,

00:08:17.059 --> 00:08:19.102
todas estas aqui,

00:08:19.135 --> 00:08:21.828
e dividir pelo número total
de predições.

00:08:21.861 --> 00:08:23.624
Como são todas 1,

00:08:23.657 --> 00:08:26.635
o jeito mais simples
de fazer isso é tirando a média.

00:08:26.668 --> 00:08:29.352
Então equality.mean.

00:08:29.787 --> 00:08:35.934
Muitas vezes você vai
se deparar com problemas

00:08:35.967 --> 00:08:38.547
com o tipo de tensor
que você tem.

00:08:38.580 --> 00:08:40.017
Este é um exemplo.

00:08:40.050 --> 00:08:44.306
O tensor equality
tem o tipo torch.ByteTensor,

00:08:44.339 --> 00:08:46.474
que diz que a média
não foi implementada

00:08:46.507 --> 00:08:48.470
para este tipo de tensor.

00:08:48.503 --> 00:08:50.999
Aqui está o nosso problema,
equality.mean.

00:08:51.495 --> 00:08:54.071
Precisamos converter isso
para um tensor float

00:08:54.104 --> 00:08:57.288
que tenha essa função
de média.

00:08:57.321 --> 00:09:01.548
Para isso,
escrevemos equality.type

00:09:01.581 --> 00:09:05.839
e damos a ele
um outro tipo de dados,

00:09:05.872 --> 00:09:07.257
FloatTensor.

00:09:07.290 --> 00:09:11.596
Isso converte o tensor equality,
que é um tensor byte,

00:09:11.629 --> 00:09:14.745
para um tensor float,
e assim obtemos a média.

00:09:14.778 --> 00:09:16.717
Agora temos a acurácia.

00:09:16.750 --> 00:09:20.936
Agora vamos rodar
o passo de validação

00:09:20.969 --> 00:09:22.641
várias vezes

00:09:22.674 --> 00:09:26.168
e também precisamos passar
pelo testloader.

00:09:26.201 --> 00:09:31.058
Quero resumir isso
em uma função própria.

00:09:32.295 --> 00:09:34.085
Fica mais ou menos assim.

00:09:34.118 --> 00:09:37.309
Definimos
a função de validação,

00:09:37.342 --> 00:09:39.727
passamos o modelo, os dados,

00:09:39.760 --> 00:09:43.154
o testloader e o critério.

00:09:43.187 --> 00:09:47.567
E algo para resumir
a acurácia...

00:09:47.600 --> 00:09:53.568
Agora vamos fazer um loop
pelas imagens e rótulos dos dados.

00:09:54.696 --> 00:09:56.639
Basicamente, estamos
fazendo um loop

00:09:56.672 --> 00:09:58.230
por todos os lotes
do testloader,

00:09:58.263 --> 00:10:02.279
calculando a perda
e a acurácia de teste,

00:10:02.312 --> 00:10:07.585
somando tudo
para retornarmos isso.

00:10:09.000 --> 00:10:10.872
Agora que temos isso
como função,

00:10:10.905 --> 00:10:14.028
podemos colocá-lo no nosso loop
de treinamento normal

00:10:14.061 --> 00:10:16.680
e medir a validação
durante o treinamento.

00:10:16.911 --> 00:10:21.426
A cada certa quantidade de passos,
que definimos em print_every,

00:10:21.459 --> 00:10:23.395
vamos fazer a validação.

00:10:23.428 --> 00:10:26.747
O que vou fazer aqui
é dizer torch.no_grad.

00:10:26.780 --> 00:10:30.147
Isso basicamente desliga
todos os gradientes

00:10:30.180 --> 00:10:32.295
de todos os tensores.

00:10:32.328 --> 00:10:35.503
Ao fazer validações,
não pensamos nos gradientes,

00:10:35.536 --> 00:10:40.475
então isso vai apenas acelerar
os cálculos da validação.

00:10:41.361 --> 00:10:45.238
Vamos pegar
a perda de teste e a acurácia

00:10:45.765 --> 00:10:48.062
da nossa função de validação.

00:10:48.690 --> 00:10:52.044
É importante também saber
que, agora que temos o dropout,

00:10:52.077 --> 00:10:55.709
não queremos que ele esteja ligado
durante a validação.

00:10:55.742 --> 00:11:00.691
Se estiver ligado,
a performance da rede será pior.

00:11:00.724 --> 00:11:02.901
Para a inferência
depois do treinamento,

00:11:02.934 --> 00:11:04.484
dropout deverá
estar desabilitado.

00:11:04.517 --> 00:11:07.254
Dropout deverá estar desabilitado
durante a validação.

00:11:07.287 --> 00:11:11.778
Podemos fazer isso deixando
o modelo no modo de avaliação.

00:11:12.783 --> 00:11:16.125
Fazemos isso com model.eval.

00:11:17.951 --> 00:11:21.557
Depois vamos reabilitar
o dropout.

00:11:21.590 --> 00:11:24.010
Fazemos isso com model.train.

00:11:24.967 --> 00:11:27.579
Para colocar a rede
em um modelo

00:11:27.612 --> 00:11:32.736
em um modo para fazer
inferência e validação,

00:11:32.769 --> 00:11:34.405
usamos model.eval.

00:11:34.438 --> 00:11:36.741
Para treinamento,
dizemos model.train.

00:11:37.597 --> 00:11:43.389
Vamos também colocar o modelo
como treinamento aqui por precaução.

00:11:44.088 --> 00:11:47.054
Agora podemos ver como está.

00:11:48.337 --> 00:11:51.816
Podemos ver que temos
os prints das perdas de teste,

00:11:51.849 --> 00:11:53.390
assim como a acurácia.

00:11:53.423 --> 00:11:57.241
A acurácia começa
bem baixa, 0,7,

00:11:57.274 --> 00:12:00.879
e, ao longo do tempo,
durante o treinamento, ela aumenta.

00:12:01.780 --> 00:12:03.568
Com a rede treinada,

00:12:03.601 --> 00:12:05.812
podemos usar isso
para inferência,

00:12:05.845 --> 00:12:08.477
portanto, novamente,
para fazer predições.

00:12:08.510 --> 00:12:11.110
É basicamente
a mesma coisa de antes.

00:12:11.143 --> 00:12:14.084
Precisamos lembrar de colocar
o modelo no modo de avaliação,

00:12:14.117 --> 00:12:16.416
desabilitar o dropout

00:12:16.449 --> 00:12:19.846
e usar torch.no_ grad
para desabilitar os gradientes,

00:12:19.879 --> 00:12:21.957
e então podemos fazer
um passo adiante

00:12:21.990 --> 00:12:24.168
e obter a probabilidade.

00:12:24.201 --> 00:12:27.520
Pegamos log_softmax daqui,

00:12:27.553 --> 00:12:30.355
pegamos o exponencial
de softmax,

00:12:30.388 --> 00:12:34.123
obtemos a distribuição
de probabilidade

00:12:34.156 --> 00:12:36.442
e vemos de fato o que temos.

00:12:36.475 --> 00:12:42.309
Na parte a seguir, vamos ver
como salvar e carregar modelos.

00:12:42.342 --> 00:12:45.495
Não faz sentido treinar
um modelo completamente novo

00:12:45.528 --> 00:12:46.911
sempre que você
precisar de um.

00:12:46.944 --> 00:12:49.315
Então o que você faz
é treinar o modelo

00:12:49.348 --> 00:12:50.914
e salvá-lo em um checkpoint,

00:12:50.947 --> 00:12:55.208
que é como o modelo de treinamento
é chamado ao salvá-lo.

00:12:55.241 --> 00:12:56.923
Salvando o modelo
em um checkpoint,

00:12:56.956 --> 00:12:59.353
você pode carregá-lo
em uma inferência

00:12:59.386 --> 00:13:00.995
ou continuar treinando.

00:13:01.028 --> 00:13:02.459
Até o próximo vídeo.

