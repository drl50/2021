WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:03.430
大家好 欢迎回来 在此视频和 notebook 中

00:00:03.430 --> 00:00:06.480
我将介绍推理和验证

00:00:06.480 --> 00:00:09.000
推理是指训练网络后

00:00:09.000 --> 00:00:12.349
我们将使用网络做出预测

00:00:12.349 --> 00:00:15.539
神经网络存在一个问题

00:00:15.539 --> 00:00:18.269
容易在训练数据上表现太好

00:00:18.269 --> 00:00:21.439
无法泛化到其他数据

00:00:21.440 --> 00:00:23.835
例如 如果用大量图像训练了网络

00:00:23.835 --> 00:00:27.269
然后输入一个没见过的图像

00:00:27.269 --> 00:00:30.704
网络在预测该图像中的内容方面将表现很糟糕

00:00:30.704 --> 00:00:36.109
神经网络从训练数据中学习了太多细节 无法泛化

00:00:36.109 --> 00:00:37.755
这称为过拟合

00:00:37.755 --> 00:00:40.460
为了在训练过程中测试是否过拟合

00:00:40.460 --> 00:00:46.535
我们用网络对测试集或验证集进行推理

00:00:46.534 --> 00:00:49.629
这个数据集看起来像训练集

00:00:49.630 --> 00:00:51.285
但是不在训练集中

00:00:51.284 --> 00:00:54.379
神经网络之前没有见过此数据

00:00:54.380 --> 00:00:57.830
这样的话 当我们在验证集上测试时

00:00:57.829 --> 00:01:03.829
可以看出网络泛化到之前没见过的数据的效果

00:01:03.829 --> 00:01:11.929
首先 正常地导入 PyTorch torchvision 等软件包

00:01:11.930 --> 00:01:16.160
再次加载 FashionMNIST 数据集

00:01:16.159 --> 00:01:18.944
你将发现 我在这里下载了测试数据

00:01:18.944 --> 00:01:23.168
我们将使用此数据进行验证

00:01:23.168 --> 00:01:25.700
这是训练数据

00:01:25.700 --> 00:01:28.120
从训练集 trainloader 中获取

00:01:28.120 --> 00:01:31.105
这是从 testloader 中获取的测试验证数据

00:01:31.105 --> 00:01:35.320
在此处 我构建了一个比到目前为止构建的网络更高级的网络

00:01:35.319 --> 00:01:40.024
因为我希望有任意数量的隐藏层

00:01:40.025 --> 00:01:43.130
我希望传入像这样的列表

00:01:43.129 --> 00:01:44.949
然后它将自动构建三个隐藏层

00:01:44.950 --> 00:01:48.810
每个层级具有这么多数量的单元

00:01:48.810 --> 00:01:54.850
为此 我使用了 nn.ModuleList

00:01:54.849 --> 00:01:58.329
它和普通列表很像 你可以向其中添加内容 扩展它 等等

00:01:58.329 --> 00:02:04.724
但是 PyTorch 模型能够跟踪

00:02:04.724 --> 00:02:07.969
你添加到此模块列表中的模块

00:02:07.969 --> 00:02:09.905
如果使用普通列表的话

00:02:09.905 --> 00:02:12.439
PyTorch 将无法跟踪

00:02:12.439 --> 00:02:17.425
你无法看到模型中的这些模块和运算

00:02:17.425 --> 00:02:19.800
我就不详细讲解原理了

00:02:19.800 --> 00:02:21.505
因为我已经写在这里了

00:02:21.504 --> 00:02:24.689
你可以在空闲时阅读这段内容

00:02:24.689 --> 00:02:31.954
对于此新网络 你需要注意的重要事项是我添加了丢弃层

00:02:31.955 --> 00:02:33.775
我们之前提到

00:02:33.775 --> 00:02:36.950
在网络训练过程中

00:02:36.949 --> 00:02:41.639
丢弃会随机删除层级之间的某些连接

00:02:41.639 --> 00:02:45.019
作用是促使网络中的单元

00:02:45.020 --> 00:02:49.490
学习输入数据中的各种特征

00:02:49.490 --> 00:02:52.659
帮助网络泛化

00:02:52.659 --> 00:02:56.764
要使用丢弃 正常地创建此运算

00:02:56.764 --> 00:02:58.469
即此模块

00:02:58.469 --> 00:03:02.995
并传入丢弃单元的概率

00:03:02.995 --> 00:03:10.200
像其他模块和运算一样 向前向传播里添加丢弃

00:03:10.199 --> 00:03:12.759
输入 self.dropout 传入一个张量

00:03:12.759 --> 00:03:16.084
要注意的第二个事项是

00:03:16.085 --> 00:03:19.965
我从前向传播里返回了 log_softmax

00:03:19.965 --> 00:03:24.429
原因是 softmax 返回的是概率分布

00:03:24.429 --> 00:03:26.860
存在的问题是很多时候

00:03:26.860 --> 00:03:30.320
获得的值非常接近 0 或非常接近 1

00:03:30.319 --> 00:03:36.474
由于将数字表示为浮点数不太精确

00:03:36.474 --> 00:03:40.659
这样会导致计算不稳定

00:03:40.659 --> 00:03:45.280
并从整体上造成很多错误

00:03:45.280 --> 00:03:49.205
解决办法是对 softmax 求对数

00:03:49.205 --> 00:03:52.630
使数字远离 0 和 1

00:03:52.629 --> 00:03:56.870
变成正态分布 例如负数 -4

00:03:56.870 --> 00:04:02.300
有助于计算变得稳定起来 提高精确率

00:04:02.300 --> 00:04:08.930
通常 处理对数空间里的概率函数轻松得多

00:04:08.930 --> 00:04:11.510
在这里 正常地创建模型

00:04:11.509 --> 00:04:15.094
输入单元 784 个 输出单元 10 个

00:04:15.094 --> 00:04:16.459
使用两个隐藏层

00:04:16.459 --> 00:04:19.314
一个有 516 个单元 一个有 256 个单元

00:04:19.314 --> 00:04:22.964
将丢弃概率设为 0.5.

00:04:22.964 --> 00:04:27.629
因为我将 log_softmax 当做输出

00:04:27.629 --> 00:04:30.904
我需要使用负对数似然损失函数

00:04:30.904 --> 00:04:33.304
使用这个作为 criterion

00:04:33.305 --> 00:04:37.220
和之前见到的交叉熵损失基本相同

00:04:37.220 --> 00:04:43.920
但是它需要输入为 log_softmax

00:04:43.920 --> 00:04:46.610
我还使用了 Adam 优化器

00:04:46.610 --> 00:04:48.319
正如之前提到的

00:04:48.319 --> 00:04:53.269
它是随机梯度下降的变体 使用了动量

00:04:53.269 --> 00:04:55.699
比普通的随机梯度下降

00:04:55.699 --> 00:04:58.800
训练速度要快

00:04:58.800 --> 00:05:03.185
现在我将演示如何编写验证代码

00:05:03.185 --> 00:05:05.115
验证代码的原理是

00:05:05.115 --> 00:05:08.780
对于验证传播 我们希望从测试数据集中

00:05:08.779 --> 00:05:14.104
获取数据并传入网络中

00:05:14.105 --> 00:05:17.405
衡量测试数据的损失

00:05:17.404 --> 00:05:19.189
还要衡量准确率

00:05:19.189 --> 00:05:23.594
即网络在之前未见过的数据上效果如何

00:05:23.595 --> 00:05:29.835
和之前一样 首先获取一些图像和标签

00:05:29.834 --> 00:05:31.904
这次从 testloader 获取

00:05:31.904 --> 00:05:34.994
而不是 trainloader 这些是测试图像

00:05:34.995 --> 00:05:37.084
调整图像大小

00:05:37.084 --> 00:05:41.364
然后将图像传入网络中

00:05:41.365 --> 00:05:44.754
这些图像来自测试集

00:05:44.754 --> 00:05:48.305
我们将获取测试集的输出

00:05:48.305 --> 00:05:56.545
我们可以更新 记录测试损失 criterion

00:05:56.545 --> 00:06:00.640
我们不打算用此损失进行反向传播

00:06:00.639 --> 00:06:03.875
只是想衡量测试集的损失

00:06:03.875 --> 00:06:05.990
这些代码用来衡量损失

00:06:05.990 --> 00:06:07.730
我们还想衡量准确率

00:06:07.730 --> 00:06:13.980
即网络在测试数据集中预测正确标签的准确率

00:06:13.980 --> 00:06:19.610
在这里 正常地计算概率

00:06:19.610 --> 00:06:22.220
输入 torch.exp()

00:06:22.220 --> 00:06:24.935
同样 输出是 log_softmax,

00:06:24.935 --> 00:06:27.550
对数的对立面是指数

00:06:27.550 --> 00:06:30.970
这样可以获得 softmax 分布

00:06:30.970 --> 00:06:33.685
到目前为止应该一切正常 不错

00:06:33.685 --> 00:06:37.415
这些是概率 检查一下

00:06:37.415 --> 00:06:41.500
大小是 64 x 10

00:06:41.500 --> 00:06:46.009
我想看看网络预测正确标签的效果

00:06:46.009 --> 00:06:50.079
我需要比较正确标签和网络预测的标签

00:06:50.079 --> 00:06:52.824
要获取网络预测结果

00:06:52.824 --> 00:06:56.620
我需要从 softmax 输出中获取最高概率

00:06:56.620 --> 00:07:00.175
输入 ps.max

00:07:00.175 --> 00:07:04.560
获取第一个维度 这里是 10

00:07:04.560 --> 00:07:09.110
作用是获取两个不同的张量

00:07:09.110 --> 00:07:12.720
第一个张量是实际概率

00:07:12.720 --> 00:07:16.570
第二个张量中的最高概率是

00:07:16.569 --> 00:07:22.209
最高概率的索引

00:07:22.209 --> 00:07:24.239
这些索引比较有趣

00:07:24.240 --> 00:07:26.829
因为会告诉我们

00:07:26.829 --> 00:07:31.039
哪个类别在 softmax 输出中的概率最高

00:07:31.040 --> 00:07:33.700
第二个张量

00:07:33.699 --> 00:07:36.439
即这个张量告诉我们预测类别

00:07:36.439 --> 00:07:39.355
输入 1 获得预测类别

00:07:39.355 --> 00:07:43.879
然后需要将它与真实标签比较

00:07:43.879 --> 00:07:47.040
调用 equality

00:07:47.500 --> 00:07:50.425
看看结果如何

00:07:50.425 --> 00:07:53.620
equality 获得另一个张量

00:07:53.620 --> 00:07:58.420
1 表示预测正确

00:07:58.420 --> 00:08:00.860
0 表示预测错误

00:08:00.860 --> 00:08:04.150
衡量准确性

00:08:04.149 --> 00:08:07.269
准确率是指预测正确的次数

00:08:07.269 --> 00:08:11.709
占预测总次数的百分比

00:08:11.709 --> 00:08:13.680
因为这些都是 1 和 0

00:08:13.680 --> 00:08:17.139
我们需要将所有正确项相加

00:08:17.139 --> 00:08:18.964
所有这些 1 相加

00:08:18.964 --> 00:08:21.909
然后除以预测总次数

00:08:21.910 --> 00:08:23.515
因为这些都是 1

00:08:23.514 --> 00:08:26.425
简单的方法是求均值

00:08:26.425 --> 00:08:28.819
输入 equality.mean

00:08:29.600 --> 00:08:33.100
很多时候

00:08:33.100 --> 00:08:37.904
张量类型会导致问题

00:08:37.904 --> 00:08:39.629
这就是一个示例

00:08:39.629 --> 00:08:44.419
张量 equality 的类型是 torch.ByteTensor

00:08:44.419 --> 00:08:48.074
错误消息指出这种张量类型没有均值方法

00:08:48.075 --> 00:08:51.145
问题出在 equality.mean 这了

00:08:51.144 --> 00:08:54.095
我们需要将这个转换为浮点张量

00:08:54.095 --> 00:08:57.415
浮点张量具有这个 mean 函数

00:08:57.414 --> 00:09:07.149
为此 输入 equality.type 传入不同的数据类型 即 FloatTensor

00:09:07.149 --> 00:09:11.629
这行代码的作用是将 ByteTensor 类型的 equality 张量

00:09:11.629 --> 00:09:16.544
转换为浮点张量 然后就可以获得均值 我们算出准确率了

00:09:16.544 --> 00:09:20.629
我们将运行这个验证传播

00:09:20.629 --> 00:09:22.544
次数很多

00:09:22.544 --> 00:09:26.115
还需要一直回到 testloader

00:09:26.115 --> 00:09:31.565
我将这部分代码封装成一个函数

00:09:31.565 --> 00:09:34.050
看起来是这样的

00:09:34.049 --> 00:09:37.394
定义 validation 函数

00:09:37.394 --> 00:09:39.845
传入模型

00:09:39.845 --> 00:09:43.149
数据来自 testloader 以及 criterion

00:09:43.149 --> 00:09:47.340
对准确率求和

00:09:47.340 --> 00:09:53.884
循环访问数据中的图像和标签

00:09:53.884 --> 00:09:58.014
循环访问 testloader 中的所有批次

00:09:58.014 --> 00:10:01.970
计算测试损失和准确率

00:10:01.970 --> 00:10:07.970
求和 然后返回这些值

00:10:08.129 --> 00:10:10.924
变成函数后

00:10:10.924 --> 00:10:16.615
放入普通的训练循环中 在训练过程中衡量验证效果

00:10:16.615 --> 00:10:21.414
每隔一定数量的时间步（由 print_ every 设置）

00:10:21.414 --> 00:10:23.079
我们将进行验证

00:10:23.080 --> 00:10:26.700
在这里输入 torch.no_grad

00:10:26.700 --> 00:10:32.270
目的是关闭所有张量的梯度

00:10:32.269 --> 00:10:33.620
因为在验证过程中

00:10:33.620 --> 00:10:36.014
我们不关心梯度

00:10:36.014 --> 00:10:40.875
这样可以加快验证算法

00:10:40.875 --> 00:10:48.120
从验证函数里获得测试损失和准确率

00:10:48.120 --> 00:10:51.480
现在还需要注意的是 我们有丢弃操作

00:10:51.480 --> 00:10:55.605
但是不希望在验证时进行丢弃

00:10:55.605 --> 00:11:00.870
如果开启的话 会使网络的性能看起来更糟

00:11:00.870 --> 00:11:04.095
因为如果要在训练之后进行推理 则需要关闭丢弃

00:11:04.095 --> 00:11:07.075
我们要确保在验证过程中关闭丢弃

00:11:07.075 --> 00:11:12.060
然后输出验证模式下的模型

00:11:12.059 --> 00:11:16.699
输入 model.eval()

00:11:17.259 --> 00:11:21.394
然后再开启丢弃

00:11:21.394 --> 00:11:24.269
输入 model.train()

00:11:24.269 --> 00:11:32.840
要使网络（模型）进入推理和验证模式

00:11:32.840 --> 00:11:34.120
我们需要使用 model.eval()

00:11:34.120 --> 00:11:37.075
如果要训练模型 则使用 model.train()

00:11:37.075 --> 00:11:43.815
为了方便衡量 还在这里设置 model.train()

00:11:43.815 --> 00:11:47.675
现在可以看看效果如何了

00:11:47.674 --> 00:11:51.509
输出了测试损失

00:11:51.509 --> 00:11:52.894
以及准确率

00:11:52.894 --> 00:11:55.439
一开始准确率比较低 0.7 左右

00:11:55.440 --> 00:12:01.195
然后当网络接受训练后 逐渐变高了

00:12:01.195 --> 00:12:03.160
网络训练之后

00:12:03.159 --> 00:12:05.899
可以用来推理了

00:12:05.899 --> 00:12:08.629
即做出实际预测

00:12:08.629 --> 00:12:11.179
一切基本和之前一样

00:12:11.179 --> 00:12:15.454
我们需要将模型放入验证模式 关闭丢弃

00:12:15.455 --> 00:12:19.430
需要使用 torch.no_ grad() 关闭梯度

00:12:19.429 --> 00:12:24.229
然后进行前向传播 获得概率

00:12:24.230 --> 00:12:27.500
在这里获得 log_softmax

00:12:27.500 --> 00:12:31.070
求指数 获得 softmax

00:12:31.070 --> 00:12:36.425
然后获得概率分布 看看实际结果是什么

00:12:36.424 --> 00:12:42.245
在下个部分 我们将学习如何保存和加载模型

00:12:42.245 --> 00:12:44.480
没必要每次需要模型时

00:12:44.480 --> 00:12:47.060
都训练一个全新的模型

00:12:47.059 --> 00:12:49.379
我们将训练模型

00:12:49.379 --> 00:12:51.980
将其保存到检查点中

00:12:51.980 --> 00:12:55.009
当你在检查点保存训练模型时 就叫做检查点

00:12:55.009 --> 00:12:58.580
将模型保存到检查点 日后可以加载它

00:12:58.580 --> 00:13:02.600
进行推理或继续训练 下个视频见

