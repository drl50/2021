WEBVTT
Kind: captions
Language: zh-CN

00:00:00.100 --> 00:00:02.700
在此视频中

00:00:02.700 --> 00:00:06.330
我将演示如何使用迁移学习

00:00:06.330 --> 00:00:10.785
训练网络正确地分类猫的图像和狗的图像

00:00:10.785 --> 00:00:13.679
我们将使用预先训练的网络

00:00:13.679 --> 00:00:16.989
检测和提取图像中的特征

00:00:16.989 --> 00:00:18.869
这种方法非常适合解决

00:00:18.870 --> 00:00:22.714
计算机视觉和很多其他领域的挑战性难题

00:00:22.714 --> 00:00:26.990
具体而言 这些网络用 ImageNet 数据集进行了训练

00:00:26.989 --> 00:00:28.424
ImageNet 是一个庞大的数据集

00:00:28.425 --> 00:00:32.009
有 100 万个有标签图像和 1000 个不同的类别

00:00:32.009 --> 00:00:36.914
这些网络使用一种叫做卷积层的结构

00:00:36.914 --> 00:00:42.960
并从在图像中看到的模式和结构中学习规律

00:00:42.960 --> 00:00:48.649
这些网络包含几十个甚至几百个不同的卷积层

00:00:48.649 --> 00:00:52.589
与你到目前为止见过的网络相比 深度极高

00:00:52.590 --> 00:00:55.760
庞大的数据集和庞大的神经网络相结合

00:00:55.759 --> 00:01:00.359
称为深度学习

00:01:00.359 --> 00:01:04.689
真正酷的是 用 ImageNet 训练这些网络后

00:01:04.689 --> 00:01:09.424
这些模型作为特征检测器 在不是 ImageNet 的图像上效果也非常棒

00:01:09.424 --> 00:01:11.674
例如

00:01:11.674 --> 00:01:17.359
你可以将这些网络应用到猫和狗的图像上 并提取出特征

00:01:17.359 --> 00:01:21.349
然后使用这些特征作为新分类器的输入

00:01:21.349 --> 00:01:25.884
并训练该分类器正确地对猫的照片和狗的照片分类

00:01:25.885 --> 00:01:30.350
你可以使用 torchvision.models 下载这些预先训练的网络

00:01:30.349 --> 00:01:33.979
导入该模块

00:01:33.980 --> 00:01:36.015
其他的和之前看到的差不多

00:01:36.015 --> 00:01:38.224
现在有模型了

00:01:38.224 --> 00:01:44.359
来自 torchvision 和 Keras 等其他深度学习框架的模型

00:01:44.359 --> 00:01:49.799
要求图像大小是 224 x 224

00:01:49.799 --> 00:01:54.864
网络一开始训练时就使用这些大小的图像

00:01:54.864 --> 00:02:00.144
还需要和训练模型时使用的标准化方法保持一致

00:02:00.144 --> 00:02:03.319
这些颜色通道是单独标准化的

00:02:03.319 --> 00:02:06.544
即红绿蓝通道 这里列出了每个通道的均值

00:02:06.545 --> 00:02:10.784
这里列出了标准差

00:02:10.784 --> 00:02:16.030
你将需要定义训练转换

00:02:16.030 --> 00:02:17.360
需要对训练数据进行转换

00:02:17.360 --> 00:02:22.315
并对测试和验证数据进行转换
37
00:02:22,314 --&gt; 00:02:26,800
像之前我演示的那样构建转换

00:02:26.800 --> 00:02:31.830
需要注意的是 图像必须是 224 x 224

00:02:31.830 --> 00:02:34.785
需要用这些均值和标准差

00:02:34.784 --> 00:02:38.349
标准化这些图像

00:02:38.349 --> 00:02:42.544
可能需要对训练图像进行数据增强

00:02:42.544 --> 00:02:44.584
作为迁移学习的示例

00:02:44.585 --> 00:02:47.564
我将演示如何使用这个叫做 DenseNet 的模型完成这些步骤

00:02:47.564 --> 00:02:50.324
加载模型

00:02:50.324 --> 00:02:54.149
输入 model = models.densenet

00:02:54.879 --> 00:02:58.389
有多个模型

00:02:58.389 --> 00:03:01.539
结尾的数字表示网络中有多少层级

00:03:01.539 --> 00:03:04.655
通常 层级越多 准确率越高

00:03:04.655 --> 00:03:06.430
我们选择 121 这个模型

00:03:06.430 --> 00:03:09.375
暂时不需要太高的准确率

00:03:09.375 --> 00:03:12.319
输入 pretrained=True

00:03:12.319 --> 00:03:16.144
如果计算机上没有该模型的话 系统将下载到计算机上

00:03:16.145 --> 00:03:19.025
看看架构

00:03:19.025 --> 00:03:23.060
可以看出这个 DenseNet 架构有个叫特征的部分

00:03:23.060 --> 00:03:27.034
由这些卷积层组成

00:03:27.034 --> 00:03:32.715
一直往下滚动 因为这是个非常深的网络 继续滚动

00:03:32.715 --> 00:03:36.349
在最后 看到叫做分类器的部分

00:03:36.349 --> 00:03:39.500
它是在末尾的一个线性转换

00:03:39.500 --> 00:03:47.099
将特征部分的特征传入 1,000 个输出单元中

00:03:47.099 --> 00:03:51.799
对于迁移学习来说 特征部分

00:03:51.800 --> 00:03:57.090
即所有这些层级在其他数据集上的效果很棒

00:03:57.090 --> 00:04:00.700
但是 这个分类器有 1000 个输出

00:04:00.699 --> 00:04:06.060
它是专门针对 ImageNet 数据集进行训练的

00:04:06.060 --> 00:04:10.145
我们需要将这部分替换为

00:04:10.145 --> 00:04:14.844
专门为我们的数据集构建的新分类器

00:04:14.844 --> 00:04:19.189
我们将用我们的数据集训练此分类器

00:04:19.189 --> 00:04:24.029
使用这里的特征作为此分类器的输入

00:04:24.029 --> 00:04:27.709
首先 我们需要冻结

00:04:27.709 --> 00:04:33.444
DenseNet 特征部分的参数

00:04:33.444 --> 00:04:38.139
我们不想训练或计算

00:04:38.139 --> 00:04:40.659
此部分的梯度

00:04:40.660 --> 00:04:43.450
因为我们只希望使其保持静态 用作特征检测器

00:04:43.449 --> 00:04:47.339
输入 for param in model.parameters()

00:04:47.339 --> 00:04:51.459
这样会检查模型中的所有参数

00:04:51.459 --> 00:04:57.060
然后输入 param.requires_grad = False

00:04:57.060 --> 00:05:00.790
这样将关闭模型中的所有参数 不计算梯度

00:05:00.790 --> 00:05:05.814
在训练步骤不会训练这些梯度

00:05:05.814 --> 00:05:09.855
现在定义分类器

00:05:09.855 --> 00:05:12.770
和之前的操作相似

00:05:12.769 --> 00:05:15.740
构建一个序列模型分类器

00:05:15.740 --> 00:05:18.949
在这里使用有序字典

00:05:18.949 --> 00:05:21.050
将第一个线性转换传入 ReLu 中

00:05:21.050 --> 00:05:23.840
再传入另一个线性转换里 获得输出

00:05:23.839 --> 00:05:27.149
这里有两个输出 一个是猫的图像 一个是狗的图像

00:05:27.149 --> 00:05:32.199
这个分类器的输入特征来自这里

00:05:32.199 --> 00:05:33.899
对于这个分类器

00:05:33.899 --> 00:05:36.810
输入特征是 1,024 个

00:05:36.810 --> 00:05:40.084
表明这个网络的特征部分

00:05:40.084 --> 00:05:44.724
输出是 1,024 个值

00:05:44.725 --> 00:05:47.230
我们想使用这些值作为分类器的输入

00:05:47.230 --> 00:05:50.980
因此这里也是 1,024 个值

00:05:50.980 --> 00:05:54.610
总之 特征部分的输出大小

00:05:54.610 --> 00:05:59.560
需要跟分类器的输入大小保持一致

00:05:59.560 --> 00:06:02.300
定义好分类器后

00:06:02.300 --> 00:06:09.920
我们需要将 DenseNet 分类器替换为我们的分类器

00:06:10.170 --> 00:06:14.480
现在 这个网络可以训练了

00:06:14.480 --> 00:06:18.730
但是问题是 现在这个神经网络深度非常高

00:06:18.730 --> 00:06:23.855
就像之前说的 这个 DenseNet 有 121 个不同的层级

00:06:23.855 --> 00:06:27.900
如果要像之前一样 尝试在 CPU 上训练

00:06:27.899 --> 00:06:29.779
训练时间会非常长

00:06:29.779 --> 00:06:33.879
因此 我们将使用 GPU 进行计算

00:06:33.879 --> 00:06:37.259
使用 GPU 后速度可以提升 100 倍或 500 倍

00:06:37.259 --> 00:06:40.319
非常惊人 

00:06:40.319 --> 00:06:45.199
和几乎所有其他框架一样

00:06:45.199 --> 00:06:50.800
PyTorch 使用库 CUDA 在 GPU 上运行网络

00:06:50.800 --> 00:06:53.655
如果你要深入了解 CUDA 请参阅此处

00:06:53.654 --> 00:06:59.719
CUDA 是一个在 NVIDIA GPU 上运行的软件库

00:06:59.720 --> 00:07:05.860
它使用这些 GPU 高效地进行线性代数计算

00:07:05.860 --> 00:07:09.545
注意 深度学习网络中的很多运算

00:07:09.545 --> 00:07:14.020
其实就是线性代数矩阵乘法

00:07:14.019 --> 00:07:18.604
使用 CUDA 在 GPU 上可以飞快地执行这些计算

00:07:18.605 --> 00:07:21.725
对于 PyTorch 来说

00:07:21.725 --> 00:07:25.810
我们使用 model.to('cuda') 将模型参数和其他张量移到 GPU 上

00:07:25.810 --> 00:07:33.899
然后使用 model.to('CPU') 将它们移回 CPU 上

00:07:34.490 --> 00:07:38.915
我将演示下速度如何

00:07:38.915 --> 00:07:44.500
比较下使用 GPU 进行前向传播和反向传播的速度及不使用 GPU 的速度

00:07:44.500 --> 00:07:47.959
这是一个正常的训练传播 之前见过

00:07:47.959 --> 00:07:51.423
定义 criterion 和优化器

00:07:51.423 --> 00:07:53.779
注意 我们不想训练特征部分

00:07:53.779 --> 00:07:57.024
只想训练分类器部分

00:07:57.024 --> 00:08:01.484
在优化器中 传入 model.classifier.parameters

00:08:01.485 --> 00:08:05.389
使用 CPU 和 CUDA 进行循环

00:08:05.389 --> 00:08:10.399
将模型转到要使用的设备上

00:08:10.399 --> 00:08:14.734
输入 model.to(device)

00:08:14.735 --> 00:08:19.800
正常地从训练加载器获取图像和标签

00:08:19.800 --> 00:08:26.750
要使用 CUDA 要使用 GPU 需要将它们移到 CUDA 上

00:08:26.750 --> 00:08:33.750
输入 inputs.to(device) labels.to(device)

00:08:34.019 --> 00:08:36.559
当设备是 CPU 时

00:08:36.559 --> 00:08:37.879
会将它们移到 CPU 上

00:08:37.879 --> 00:08:39.299
当设备是 CUDA 时

00:08:39.299 --> 00:08:41.699
会将它们移到 GPU 上

00:08:41.700 --> 00:08:45.395
这些就是让网络在 GPU 上运行

00:08:45.394 --> 00:08:49.370
要更改的所有代码

00:08:49.370 --> 00:08:55.565
比较在 CPU 上和在 GPU 上的速度

00:08:55.565 --> 00:08:57.480
可以看出节省了大量时间

00:08:57.480 --> 00:09:04.115
对于一个批次来说 在 CPU 上需要用时 5 秒以上 在 GPU 上只需 9 毫秒

00:09:04.115 --> 00:09:07.134
改进了很多

00:09:07.134 --> 00:09:09.950
我们可以编写设备不可知代码

00:09:09.950 --> 00:09:13.509
如果机器上有 CUDA 则会自动使用 CUDA

00:09:13.509 --> 00:09:18.500
输入 torch.device 如果 CUDA 可用 则使用 CUDA

00:09:18.500 --> 00:09:24.000
否则使用 CPU 这个变成 device 变量

00:09:24.000 --> 00:09:27.789
每次使用张量或模型时

00:09:27.789 --> 00:09:32.304
直接输入 tensor.to(device) 或 model.to(device)

00:09:32.304 --> 00:09:34.379
如果已经在 CPU 上

00:09:34.379 --> 00:09:35.519
在保留不动

00:09:35.519 --> 00:09:38.674
如果已经在 GPU 上 则保留不动

00:09:38.674 --> 00:09:40.620
如果不在的话 则移到相应的设备上

00:09:40.620 --> 00:09:44.585
从现在开始 将由你来完成模型训练

00:09:44.585 --> 00:09:48.350
流程几乎不变 但是现在仅训练

00:09:48.350 --> 00:09:51.950
在这里定义的分类器

00:09:51.950 --> 00:09:57.330
并且使用 GPU 加油

